---
title:        "`r DODschools::noTouch('metadata.yml')$document$title`"
designator:   "`r DODschools::noTouch('metadata.yml')$document$designator`"
doctype:      "`r DODschools::noTouch('metadata.yml')$document$type`"
pages:        "`r DODschools::noTouch('metadata.yml')$document$pages`"
abstract:     "`r DODschools::noTouch('metadata.yml')$abstract`"
dedication:   "`r DODschools::noTouch('metadata.yml')$dedication`"
acknowledge:  "`r DODschools::noTouch('metadata.yml')$acknowledgement`"
vita:         "`r DODschools::noTouch('metadata.yml')$vita`"
degree:       "`r DODschools::noTouch('metadata.yml')$degree`"
program:      "`r DODschools::noTouch('metadata.yml')$program`"
distro1:      "`r DODschools::noTouch('metadata.yml')$distro_thesis[1]`"
distro2:      "`r DODschools::noTouch('metadata.yml')$distro_thesis[2]`"
author:
  name:       "`r DODschools::noTouch('metadata.yml')$author$fullname`"
  dept:       "`r DODschools::noTouch('metadata.yml')$author$dept`"
  rank:       "`r DODschools::noTouch('metadata.yml')$author$rank`"
  service:    "`r DODschools::noTouch('metadata.yml')$author$service`"
  prevdegree: "`r DODschools::noTouch('metadata.yml')$author$currentDegree`"
  email:      "`r DODschools::noTouch('metadata.yml')$author$email`"
advisor:
  name:       "`r DODschools::noTouch('metadata.yml')$advisor$name`"
  department: "`r DODschools::noTouch('metadata.yml')$advisor$department`"
  rank:       "`r DODschools::noTouch('metadata.yml')$advisor$rank`"
  service:    "`r DODschools::noTouch('metadata.yml')$advisor$service`"
  degree:     "`r DODschools::noTouch('metadata.yml')$advisor$currentDegree`"
  phone:      "`r DODschools::noTouch('metadata.yml')$advisor$phone`"
  email:      "`r DODschools::noTouch('metadata.yml')$advisor$email`"
reader1:
  name:       "`r DODschools::noTouch('metadata.yml')$reader1$name`"
  department: "`r DODschools::noTouch('metadata.yml')$reader1$dept`"
  rank:       "`r DODschools::noTouch('metadata.yml')$reader1$rank`"
  service:    "`r DODschools::noTouch('metadata.yml')$reader1$service`"
  prevdegree: "`r DODschools::noTouch('metadata.yml')$reader1$currentDegree`"
# reader2:
#   name:       "`r DODschools::noTouch('metadata.yml')$reader2$name`"
#   department: "`r DODschools::noTouch('metadata.yml')$reader2$dept`"
#   rank:       "`r DODschools::noTouch('metadata.yml')$reader2$rank`"
#   service:    "`r DODschools::noTouch('metadata.yml')$reader2$service`"
#   prevdegree: "`r DODschools::noTouch('metadata.yml')$reader2$currentDegree`"
# reader3:
#   name:       "`r DODschools::noTouch('metadata.yml')$reader3$name`"
#   department: "`r DODschools::noTouch('metadata.yml')$reader3$dept`"
#   rank:       "`r DODschools::noTouch('metadata.yml')$reader3$rank`"
#   service:    "`r DODschools::noTouch('metadata.yml')$reader3$service`"
#   prevdegree: "`r DODschools::noTouch('metadata.yml')$reader3$currentDegree`"
sf298name:    "`r DODschools::noTouch('metadata.yml')$author$sf298name`"
contractnum:  "`r DODschools::noTouch('metadata.yml')$sf298$contractnum`"
grantnum:     "`r DODschools::noTouch('metadata.yml')$sf298$grantnum`"
prognum:      "`r DODschools::noTouch('metadata.yml')$sf298$programnum`"
projnum:      "`r DODschools::noTouch('metadata.yml')$sf298$projectnum`"
tasknum:      "`r DODschools::noTouch('metadata.yml')$sf298$tasknum`"
worknum:      "`r DODschools::noTouch('metadata.yml')$sf298$workunitnum`"
keywords:     "`r DODschools::noTouch('metadata.yml')$sf298$keywords`"
sponsor:
  title:    "`r DODschools::noTouch('metadata.yml')$sf298$sponsor$title`"
  subtitle: "`r DODschools::noTouch('metadata.yml')$sf298$sponsor$subtitle`"
  address1: "`r DODschools::noTouch('metadata.yml')$sf298$sponsor$address1`"
  address2: "`r DODschools::noTouch('metadata.yml')$sf298$sponsor$address2`"
  phone:    "`r DODschools::noTouch('metadata.yml')$sf298$sponsor$phone`"
  email1:   "`r DODschools::noTouch('metadata.yml')$sf298$sponsor$email1`"
  email2:   "`r DODschools::noTouch('metadata.yml')$sf298$sponsor$email2`"
  acronym:  "`r DODschools::noTouch('metadata.yml')$sf298$sponsor$acronym`"
  rptnum:   "`r DODschools::noTouch('metadata.yml')$sf298$sponsor$report_number`"
graddate:   "`r DODschools::noTouch('metadata.yml')$grad_date`"
date:       "`r format(Sys.Date(), '%B %Y')`"
sf298_date: "`r format(Sys.Date(), '%d-%m-%Y')`"
dissertation: "`r DODschools::noTouch('metadata.yml')$dissertation`"
cite_style: "`r DODschools::noTouch('metadata.yml')$cite_style`"
cite_shape: "`r DODschools::noTouch('metadata.yml')$cite_shape`"
num_cite:   "`r DODschools::noTouch('metadata.yml')$num_cite`"
output: 
  DODschools::afit_thesis:
    includes:
      in_header:    scripts/tex/in_header.tex
      before_body:  scripts/tex/before_body.tex
      after_body:   scripts/tex/after_body.tex
    fig_caption: yes
    keep_tex: yes
header-includes:
  - \usepackage{float}
  - \usepackage{longtable}
---
```{r message=FALSE, warning=FALSE, include=FALSE}
pacman::p_load(devtools,
               knitcitations,
               RefManageR,
               xtable,
               sas7bdat,
               dplyr,
               survival,
               flexsurv,
               knitr,
               formattable,
               data.table,
               kableExtra,
               survminer,
               gridExtra,
               png,
               grid,
               Gmisc,
               kableExtra)
library(knitcitations)
library(RefManageR)
library(xtable)
library(sas7bdat)
library(dplyr)
library(survival)
library(flexsurv)
library(knitr)
library(formattable)
library(data.table)
library(kableExtra)
library(survminer)
library(gridExtra)
library(png)
source('scripts/R/setup.R')
installr::install.github("Auburngrads/DODschools")
options(knitr.table.format = "latex")
options(kableExtra.latex.load_packages = FALSE)
source('scripts/R/setup.R')
BIB <- RefManageR::ReadBib('C:/Users/ZKane/OneDrive/Documents/KaneThesis/references/my_bib.bib')
knitcitations <- BIB[title = 'knitcitations']
refmanager    <- BIB[title = 'RefManageR']
pressure      <- BIB[key = 'randolph2016']
knitcitations::cite_options(citation_format = 'pandoc')
#BIB <- ReadBib('references/my_bib.bib')
#knitcitations <- BIB[title = 'knitcitations']
#refmanager    <- BIB[title = 'RefManageR']
#pressure      <- BIB[key = 'randolph2016']
#cite_options(citation_format = 'pandoc')
```

# Introduction

## Background

Over the course of human history, the world's countries have continually transitioned in and out of states of internal and foreign conflict. These conflicts range from small unarmed bouts to deadly world wards and have become a major area of study for nations trying to understand and ultimately mitigate the threats brought on by potential conflict and regional instability. The Heidelberg Insititute for International Conflict Research (HIIK) identified 385 conflicts globally in 2017 `r citep(BIB[key="hiik"])`. Each nation in a defined state of conflict experienced varying levels of intenisty, nations involved, and influential factors. Due to the uniqueness of each individual conflict, there have been multiple research efforts on building accurate predictive models of armed conflict. Predictive models have incorporated every world conflict to conflict within a single nation. Rooted in a United States military commbatant command approach to grouping nations, predcitive models of country conflict achieved highly accurate results. Recent studies largely focused on finding the most influential variables in predicting the observed data, while this still begs the question of how to predict future data and determine conflicts that will emerge or stagnate. 

This research examines predicting country's conflict based on generated future data of a world region. Future alternatives of a nation's conflict transitions were calculated for two world regions historically stricken with conflict and intially grouped based on location and data similiarity. With a forecasted outline of a region's conflict transtions, a nation's can improve their resource allocation to address a changing future conflict intensities.

## Problem Statement

Fill the missing observations in the data set utilized by Neumann's research by testing and identifying each variables' optimal imputation method. Develop regression models for the each variable of interest for the two selected world regions. Iteratively create future alternatives for country transitions up to 2030 and solve for each nation's yearly conflict status. Perform region specific what-if analysis to test the robustness region's future conflict alternatives.

## Research Objectives

The objective of this study is to implement the optimal imputation techniques that addresses Neumann's data's missingness by region and to develop future alternatives of country conflict landscape using an interative imputation style explanatory forecasting method. 

## Research Questions

This study seeks to answer the following research questions on the future alternatives of conflict transitions in the Arab and South East Asia regions of the world. 

**Question 1**

How should the data set utilized in the Neumann study be imputed?

**Question 2**

How can we develop regression models for each variable of interest in a given region?

**Question 3**

What insights, nations succeptible or impervious to conflict transitions are identified by the generated regional conflict future alternatives?

**Question 4**

How robust are the future alternatives of conflict tranistions to the what-if analysis scenarios tested for each region?

## Assumptions and Limitations

This study is based on four underlying assumptions. The first assumption, similiar to other conflict prediction research, is that the data analyzed is accurate and describes the commonalities between countries and their conflicts. The geographical groupings by region identified by the Neumann `r citep(BIB[key="neumann"])` study were assumed to be suitable commonality in terms of economy, geography, ethnic, and religious demographics to develop future alteratives. The third assumption is that the variables identified as significant for Neumann's `r citep(BIB[key="neumann"])`. conflict logitstic regression models are the only relevant variables for predicting conflict during the duration of future years. Lastly, this study assumes that the predictive models found by Neumann are accurate and uneffected over the years by the changing generated future data. 

Data availibility limitated this research by forcing multiple imputation techniques to be applied to the gaps observed for certain variables. After combining multiple opensources, over half of the variables required imputation of their missing values. With a largely imputated data set then being used to generate future data, the level of uncertainty behind the numbers worsened the adequacy of the regression models. Additionally, computing power and time limited the variables extrapolated to only those found significant in a region's conflict prediction models as opposed to all the variables availible. A greater degree of fidelity could have been achieved by developing the future alternatives with more information provided by all of the variables recorded. Despite the inherent limitations of this research, it proceeds to provide national leadership with complete data, a tested forecasting method, and future, realistic country conflicts to consider when developing foreign policy and security stategies.

## Overview

This thesis is organized into 5 chapters including this introduction chapter, Chapter 1. Chapter 2 contains a literature review of prominent studies and methods relating to this research. Chapter 3 discusses the methodology of the study to impute the data and develop the alternative futures of conflict transitions. Chapter 4 details the results and analyses, and chapter 5 offers final conclusions, and possibilities for future research.

# Literature Review

## Overview

The purpose of this chapter is to provide a background of the previous influential research done on country conflict prediction that this research is built upon as well as an explanation of the existing contributions made to predict based future data. This chapter is broken down into three main sections: existing nation-state conflict modeling, applied imputation techniques, and related forecasting applications. The first section of this chapter focuses on the development of predictive models for nation-state conflict that lead to the very model employed by this research. The second section identifies similar imputation methods and comparison stategies that informed this research's handling of missing data. The final section provides a summary of related applications of explanatory forecasting efforts that this research's own generative alternative future method. This chapter ultimately aims to cover literature about the main models, methods, and applications related to this research.

## Previous Nation-State Conflict Models

Predicting world conflict has been a problem addressed by multiple studies. There have been different prediction methologies where researchers have defined conflict, the influential variables, and how best to group countries prior to predicting their conflicts. There have been varying accuracies achieved by these predictive modeling efforts. This section outlines the progress already made in predicting countries conflict status which is the basis of this research's generation of alternative world conflict futures.

The 2013 research, _Learning from the Past and Stepping into the Future: Toward a New Generation of Conflict Prediction_, focused on the benefits that prediction models of political conflict in a complicated geopolitical landscape could provide  `r citep(BIB[key="ward"])`. The authors defended the importance of country conflict prediction and identified limitations in previous research. Previous research had fixated on including statistically significant variables while overlooking a variable's impact on a the model's overall predictive accuracy. Ward `r citep(BIB[key="ward"])` developed a model of behavioral and instituational variables to predict the cumulative probability of civil war six months prior prior to it's onset in various countries. This hierarchial logit model's slope and intercept differed depending on different groups of nations and achieved a accurately predicted civil wars 95\% of the time. Ward's `r citep(BIB[key="ward"])` research was the first to put a greater deal of importance on prediction accuracy in addition to just building models with siginificant variables. Until the Ward `r citep(BIB[key="ward"])` study and Goldstone's `r citep(BIB[key="goldstone"])` efforts, conflict prediction models' precdition accuracies were capped at limited around 50\% `r citep(BIB[key="shallcross"])`. 

The study, _A Global Forecasting Model of Political Instability_, conducted by Dr. Jack Goldstone `r citep(BIB[key="goldstone"])` for the U.S. Central Intelligence Agency's Directorate of Intelligence predicted the onset of political instability two years prior to the conflict's start . The research took open source global data from 1955 to 2003 and performed a variety of predictive techniques to achieve 80\% accuracy distinguishing between countries that experienced instability from those that remained a constant level of political  `r citep(BIB[key="goldstone"])`. Goldstone's  `r citep(BIB[key="goldstone"])`  study found a nonlinear five-category measure of regime type to be the most powerful predictor rather than economic conditions, demography, or geography. Country conflict, the dependent variable, was defined as a revolutionary war, ethnic war, adverse regime changes, or genocides and politicides  `r citep(BIB[key="goldstone"])`. Of the predictive event history models, logistic regression, neural networks, and Markov processess tested, the simple logisitc regression model performed best with only four independent variables. These results gave insight for future researchers to the importance of fewer, major variables in reducing the unexplained variance of the conflict models as well as logistic regression being a favorable method political instability prediction. Goldstone's model was built on a world scale and ignored the differences between nations' locations. In fact, the sole region modeled seperately, Africa, included different variables for predicting country conflict which indicates the pertinence of regional differences `r citep(BIB[key="goldstone"])`. 

The Center for Army Analysis's research _Recognizing Patterns of Nation-State Instability that Lead to Conflict_ analyzed the influential factors in predicting country conflict relevant to Army operations. Shearer's work intiially mapped the top four intensity levels of an older, slightly different version of the HIIK conflict intensity into to two categories: peace and conflict `r citep(BIB[key="shearer"])`. This indicator of a nation's conflict status was the model's dependent variable, and thirteen variables from unclassified data on the diplomatic, social, economic, and military factors of each country acted as the regressors `r citep(BIB[key="shearer"])`. Pricipal component analysis was applied to better visualize the data in a reduced three dimensional feature space. The study further used a smoothing algorithm to forecast future vectors, and with k-Nearest Neighbors and Nearest Centroid algorithm, Shearer `r citep(BIB[key="shearer"])` obtained a classification accuracy of 85\% for the stability of a nation over time. The reaserch introduced an understandable way to view the data and define, on a global scale, a nation's likelihood of conflict while predicting conflict further into the future with comparable precision. 

_Predicting Armed Conflict, 2010-2050_ predicted global and regional incidencies of armed conflict using a multinominal logit model trained on cross-sectional data on 169 countries from 1970-2009 `r citep(BIB[key="hegre"])`. The model predictions were on the likelihood of a nation's transition between no conflict, minor conflict, and major conflict. The three transition states were determined by the combat related deaths per year, and preictions calculated by simulating the behavior of the conflict variable implied by the estimates from their model `r citep(BIB[key="hegre"])`. The regional based model building strategy, taken by the research accounted for countries' geographically driven differences. The world was divided into eight regions from a compressed version of the United Nations regional grouping and included unique regressors for each region. Six seperate models were developed using varying combinations of independent variables that emphasized the influence of conflict history, country development, and neighboring behavior on conflict status `r citep(BIB[key="hegre"])`. The simulated future data was based on proposed scenarios and projections of demographic trends over time with the the multinomial logit coefficients changing yearly until simulating to convergence `r citep(BIB[key="hegre"])`. This study set a precedent of a multi level conflict matrix that allowed for the inclusion of predicting ongoing conflicts. The study simultanously predicts escalation, onset, and termination of conflicts which expands the work's application to global and regional prediction. 

Building on previous theses and leading to the very predictive model featured in this research, Boekestein  `r citep(BIB[key="boekestein"])` first adapted the Heidelberg Institute for International Conflict (HIIK) Research "Levels of Conflcit" as the dependent variable of his logisitic regression. Violent conflicts were defined by the highest three HIIK scores (3-violent crisis, 4-limited war, 5-war) while a country not in conflict scored on the lower three HIIK levels (0-no conflict, 1-dispute, 2-non-violent conflict)  r citep(BIB[key="boekestein"]) . Boekestein `r citep(BIB[key="boekestein"])` data compiled various open sources to encompass twenty six variables that were used to build individual parsimonous models for the six regions identified from insights from credible statistician Hans Rosling. The study found influential variables for each region's model through variance inflation factor screening and correlation testing which produced models with a maximum prediction accuracy of 76\% `r citep(BIB[key="boekestein"])`. With a reduced logistic regression cutoff of 0.28 as opposed to the default 0.5, Boekestein `r citep(BIB[key="boekestein"])` constructed seperate regional models with varying subsets of variables that attained postdictive accuracy around 80\%. This studies resulting conflict prediction capabilities were comparable to the previously mentioned Center for Army Analysis research.

Shallcross's `r citep(BIB[key="shallcross"])` work expanded on the Boekestein with the introduction of a nation specific Markov Chain model to forecast nations' tendencies to transition in or out of conflict based on the country's current conflict status. The markovian model comprised of two states mapped from the HIIK conflict intensity scoring: in conflict and not in conflict `r citep(BIB[key="shallcross"])`. The regional logistic regression models' dependent variables were the transition of conflict status, and double the models were created that accounted for the two possible conflict states of a country the year prior. With the field being increasely curious how nearby conflicts effect a nation's environment, Shallcross  `r citep(BIB[key="shallcross"])` considered independent variables for the conflict intensity of nations directly sharing a border and the percent of the total border shared with a given nation. Contingent upon a country's conflict status the year prior, an "in conflict" or "not in conflict" predictive model would be executed to find the probability of that a country would change or remain conflict statuses  `r citep(BIB[key="shallcross"])`. Shallcross `r citep(BIB[key="shallcross"])` achieved overall prediction accuracies above the 80% benchmark for his models and established the two state predictive modeling methodology practiced by this research.

Expanding on the work of Shallcross `r citep(BIB[key="shallcross"])`, Leibyâ€™s `r citep(BIB[key="leiby"])` study specifically focused on incorporating environmental factors, specifically water and neighboring country conflict, into prediction models and analyzing their effects on prediction accuracy. For the same regions as Shallcross `r citep(BIB[key="shallcross"])` and Boekestein  `r citep(BIB[key="boekestein"])`, Leiby  `r citep(BIB[key="leiby"])`  introduced two additional indenpendent variables into the conditional logistic regression equations that predicted the of a nation's conflict. The introduced variables were the percentage of the total number of bordering countries in conflict and a binary variable indicating if at least one bordering nation was in a state of conflict `r citep(BIB[key="leiby"])`. Bidirectional stepwise selection based on each variables' G statisitics informed the variable reduction methods used for each region's models  `r citep(BIB[key="leiby"])`. The environmental factors were forced into the models to identify their impact, but incorporating them only marginally improved model parsimony and predictive accuracy. Leiby's `r citep(BIB[key="leiby"])` models were still able to was able to achieve a training classification accuracy of 92%.

Taking advantage of the previous predicting progress made, _Forecasting Country Conflict within Modified Combatant Command Regions using Statistical Learning Methods_ built the most recent conflict transition predictive models used within this research  `r citep(BIB[key="neumann"])` . Neumann's `r citep(BIB[key="neumann"])`  models were specific to the regions identified by a modified k-means clustering algorithm that differentiated countries based on data similarities and geographic proximity. This grouping of nations improved each regions' conditional logistic regression models that predicted the likelihood of a country to transition into or out of conflict `r citep(BIB[key="neumann"])`. These new regional groupings' models were compared to models built for the current Combatant Command Regions and yielded training data classification accuracies exceeding 89\% `r citep(BIB[key="neumann"])`. Neumann's `r citep(BIB[key="neumann"])` methodology of grouping countries into modified verison of the Combatant Commands improved the overall forecasting ability of conflict transitions, the best found in literature to date, and the models utilized to predict country conflict transitions in this research.

## Applied Imputation Techniques

There are varying degrees of complexity taken by researchers trying to fill the missing gaps in their data. This section aims to explore a few of the varying imputation approaches and methodologies practiced recently. There is no consensus on an optimal way to impute data, but by understanding related imputation efforts, this research is better informed to decide on a proven imputation technique and repeat it on any and all foreseen data missingness.    

In the study, _Overview of Missing Physical Commodity Trade Data and Its Imputation Using Data Augmentation_, incomplete physical commoditiy trade databases are imputed using simplier, traditional methods and computationally complex stochastic methods `r citep(BIB[key="farhan"])`. The incomplete commodity trade data impedes ther proper analysis of trade flow between countries and stemmed from non-compliance of reporter countries, confidentiality issues, delays in precessing of data, or erroneous reporting `r citep(BIB[key="farhan"])`. The imputation methods tested were categorized into deterministic single imputation approaches and stochastic imputation approaches. The deterministic methods included imputation by mean, interpolation, and regression while the stochastic driven apporaches included stochastic regression and more complex iterative processes. The study identified a key advantage to the stochastic apporach is that instead of using a point estmate as the impute value, a distribution of missing data through mulitiple imptuations is obtained to reflect uncertainity and maintain the variability in the original data which is overlooked by the deterministic methods `r citep(BIB[key="farhan"])`. In the case study, China, France, the United Kingdom, and the United States] imports of ten primary commodities were considered for the period 1978-2010 `r citep(BIB[key="farhan"])`. The percent missingness for the ten variables ranged between 3.72\% and 15.69\%, and initially the data was transformed to be normal despite most of the more complex imputation techniques being robust even when the normality assuption is violated `r citep(BIB[key="farhan"])`. Auxiliary variables were included in the multiple imputations based on the improved quality of imputations and reduced bias of the estimates their correlations with incomplete variables `r citep(BIB[key="farhan"])`. This was a driving factor that inspired this research's decision to impute data with all availible variables in a region before reducing the data set to just variables of interest. The multiple imputation method tested in the study and is explained in full detail within this research's methodology chapter. Synethesized estimates were compared against actual observed observations using the normalized root mean square error. The study found that the mulitple imputation out-performed the substution by mean, interpolation, and regression methods `r citep(BIB[key="farhan"])`. The mean imputation method was found to generate imputed values with the highest amount of deviations from the observed values, and the proposed multiple imputations yielded the smallest errors `r citep(BIB[key="farhan"])`. 

_On Multivariate Imputation and Forecasting of Decadal Wind Speed Missing Data_ applies multiple imputations by chained equations and time series forecasting on the Department of Meteorology's daily wind speed data from 1995 through 2008 r citep(BIB[key="wesonga"]). Markov Chaine Monte Carlo (MCMC) imputation generated random draws from multidimensional probability distributions via Markov chains, sequence of random variables in which the distribution of each element depends on the value of the previous one r citep(BIB[key="wesonga"]). Through MCMC, the research simulated the entire joint posterior distribution of the unknown quatitites and obtained simluation based estimates of posterior parameters of interest. 28\% of the months of wind observations were missing r citep(BIB[key="wesonga"]). MCMC was applied in a variable by variable fashion to fill in the unobserved instances, and a time series analysis on the imputed data was performed in order to then make forecasts. Forecasts were made using exponential smoothing using an additive Holt-Winters prediction function with constant level and no seasonality assumptions r citep(BIB[key="wesonga"]). When analyzing the differences between the imputed and original wind speed data, the study tested the standard of the multiple imputations to preserve the structre and probability functions of the imputed data. A t test was completed and found no significant difference between the original and imputed wind speed datasets, confirming the high level of reliability for multiple imputations r citep(BIB[key="wesonga"]). A similiar test comparing the original to imputed data was completed by this study to determine the superior imputation method for a given variable.

In the article, _Imputation for Multisource Data with Comparison and Assessment Techniques_, ridge regression and a state-space model, both of which take advantage of potential correlations between data are tested for imputation of multisource data r citep(BIB[key="casleton"]). The data comes from an experimental facility for a non-regularly occurring events that collects information from four sensors: seismic, acoustic, surveillance video, and domain-name system log data r citep(BIB[key="casleton"]). The imputation by ridge regression is a constrained version of least squares regression that shrinks coefficient estimates towards zero until reaching a fit and predicts the unobserved value of certain feature (CITE). Dynamic linear models were the state-space technique that allows relationships between features to vary with time r citep(BIB[key="casleton"]). The imputation methods were compared by the mean absolute deviation between the imputed and observed values. The study found that the imputation using a dynamic linear model achieved the highest accuracy and most precise confidence intervals around the imputed values which was an additional way the study assessed imputation techniques r citep(BIB[key="casleton"]).

## Related Forecasting Applications

Making predicitions on future data is a complicated field with inherent uncertainty involved. This section covers a few existing forecasting efforts similiar to the alternative futures developed in this research. By understanding the related applications of forecasting, context is provided into the departures this research makes from current forecasting field. 

For country conflict prediction, Hegre `r citep(BIB[key="hegre"])` had generated predictions for future data from the years 2010 to 2050 using simulated data by projections of predictor variables, as provided by the UN World Population Prospects and the International Institute of Applied Systems Analysis. Consulting expert opinion to develop future data with Hegre's conflict status predictive models showed an overall decline in global incidences of violent crimes. The anlaysis attributed this decline to the improved country developmental factors: infant mortality rate, education, and youth bulges `r citep(BIB[key="hegre"])`. It should be noted that Hegre's long term precitions are built upon projections and should be interpreted on as long term global or possibly regional conflict trends rather than specific national level predictions `r citep(BIB[key="shallcross"])`.

_Non-parametric regression for space-time forecasting under missing data_ analyzes real time spatio-temporal datasets experiencing missingness due to long periods of unobserved sensors and tries to forecast the future unit journey time values of road links in central London, UK using two non-parametric regression models: kernel regression and K-nearest neighbours r citep(BIB[key="haworth"]). Traffic monitoring networks present a real time setting where imputed data is immediately required for long term forecasting that informs road users of future traffic conditions from the current road network's characteristics r citep(BIB[key="haworth"]). Kernel regression is a non-parametric regression technique that is used to estimate the conditional expectation of a random variable. Forecasts are produced as a combination of historical data points and weighted accordingly by the kernel function r citep(BIB[key="haworth"]). The London Congestion Analysis Project network experiences missing data which is imputed using a process called patching, replacing the missing values with estimates which vary according to the number of points that are missing in succession r citep(BIB[key="haworth"]). Both models performed well for forecasting spatio-temporal datasets that exhibit high levels of missing data and were simple by only having only a single parameter to train and using the single upstream and downstream neighbours to forecast.

Taking a different approach, _A Stepwise Regression Method for Forecasting Net Interchange Schedule_ presents a stepwise regression method for forecasting net interchange schedules r citep(BIB[key="vlachopoulou"]). These power grid operational schedules are the sum of the electric power exchanges between an Independent System Operator/Regional Transmission Organization and its neighbors. The paper proposed using stepwise regression which iteratively adds and removes the explanatory variables according to their significance in the training data to find a reduced order model that is computation effective and can forecast the future net interchange schedule. Akaike Information Criterion was used to evaluate each explanatory variable's ability to increase the goodness of fit of the statistical model. Stepwise regression was modified slightly modified by adding a set of random variables whose values are drawn from normal and uniform distributions. The number of random variables was the same as the observed explanatory variables and acted as empirical stopping criterion of the stepwise regression. After some number of iterations, if the regression added more than three random explanatory variables to the regression model, the regression process stopped. A sliding window approach was followed to create training and testing datasets, and  the study found that the statistical significance  of the parameters depended on the net interchange schedule forecasting horizon. The regression based on the reduced explanatory variable set produced a model with smaller forecasting error in less computational time versus the using the full explanatory variable set. Similarly, this research will develop alternative futures using a reduced set of variables that has been identified by Neumann (CItE) to be significant for predicting conflict transition in a given region. 

Pedroza's research takes a Bayesian approach to forecast mortality rates for the period 1990-1999 based on U.S. male mortality data from 1959-1989. Forecasts of mortality rates are vital to government agencies' development of health policies and allocation of government services' funds. Mortality rates are the ratio of deaths to mid-year population size for a given interval of age and time. A previously developed method by Lee and Carter forecasts age-specific log-mortality rates with a  multivariate normal model and estimates the parameters using singular value decomposition with a random walk model with drift to forecast their vector of future levels of mortality index. The Bayesian model reformulated Lee-Carter's method as a state-space model and incorporated a Markov chain Monte Carlo method to draw samples from the join posterior distribution of the parameters and to form the posterior predictive distribution of the log-mortality rates. the model iteratively completes two steps, draw parameters from their respective conditional distributions and simulates the level of mortality state vector. The Bayesian formulation of the Lee-Carter model created wider prediction intervals which more accurately reflected the forecasting error associated with the model and underlying uncertainty of the data and technique. This research doesn't go to such extensive modeling lengths but still aims to capture the uncertainties present.

Zhang's research tested a combined autoregressive integrated moving average (ARIMA) and artificial neural networks (ANN) forecasting model to take advantage of the unique strengths of each model. The study performs time series forecasting in which past observations of the same variable are collected and analyzed to develop a model describing the underlying relationship from which the model extrapolates the time series into the future. ARIMA models can represent several different types of time series but are limited by the pre-assumed linear form of the model. In an ARIMA model, the future value of a variable is assumed to be a linear function of several past observations and random errors. ANN have the flexible data-driven capability of modeling nonlinear data thus erasing the need to specify a particular model form. An ANN model performs a nonlinear functional mapping from the past observations of a variable to the future value. A proposed hybrid approach that considers a time series composed of a linear autocorrelation structure and a nonlinear component using both models and applies ARIMA to the linear component and ARIMA to model the nonlinear related residuals from the ARIMA application. Three data sets were chosen to demonstrate the proposed hybrid method: nonlinear sunspot data, Canadian lynx trapping data, and British pound/US dollar exchange rate data. The study found with the three data sets that the hybrid model out performed each component model used in isolation. The research emphasized understanding the initial structure of the data to apply the appropriate model and accurately forecast data.

## Summary

This literature review provides background on previous models and techniques used to develop a data set that adequately explains country conflict, how border conflicts affects a nation's likelihood of entering into a state of conflict, and what are the best ways to group countries considering their conflict statuses. Logistic regression was the most effective way to predict and model conflict which is the method utilized later by this research. Imputing data has been studied in many different fields with applying simple to complex strategies that influence the imputation technique chosen by this research. Making predictions on future data sets or forecasting has been attempted and applied with varying success. Uncertainty in the data and other factors drive the forecasting models explained to inject some chance in their projected futures.    

# Methodology

## Overview

This research explores imputation techniques to first fill missing gaps int the data and develop linear regression models to develop future alternatives of nation-state conflict for two major world regions. Section 3.2 describes the methodology used to develop the data set and imputation methods used to complete the data's missing observations. Section 3.3 outlines the development and building procedures for the linear regression models for each variable of interest. Section 3.4 

```{r, engine="tikz", eval = TRUE, fig.cap = "Methodology Overview", echo=FALSE}
\usetikzlibrary{shapes,arrows}
\pagestyle{empty}

\tikzstyle{block} = [rectangle, draw, fill=grey!20, 
text width=11em, text centered, rounded corners, minimum height=4em]

\begin{tikzpicture}[scale = .85, transform shape, node distance = 2cm, auto, >= triangle 60]
    % nodes
    \node [block] (init) {Collect data set};
    \node [block, right of = init, node distance = 5cm] (sec) {Imputation selection and implementation};
    \node [block, right of = sec, node distance = 5cm] (third) {Individual\\variable regression model generations};
    \node [block, below of = init, node distance = 3.5cm] (four) {Single step\\iterative future method};
    \node [block, right of = four, node distance = 5cm] (fifth) {Utilize country conflict logistic\\regression models};
    \node [block, right of = fifth, node distance = 5cm] (six) {Replicate for a given future data set};
    \node [block, below of = four, node distance = 3.5cm] (sev) {Multiple future data sets};
    \node [block, right of = sev, node distance = 5cm] (eight) {Statistical analysis of each future data set};
    \node [block, right of = eight, node distance = 5cm] (nine) {Conduct what if future analysis};

    \draw[-triangle 60] (init) -- (sec);
    \draw [->] (sec) -- (third);
    \draw [->] (third) |- ([xshift = 0cm, yshift = -1.75cm].northwest) -- (four);
    \draw [->] (four) -- (fifth);
    \draw [->] (fifth) -- (six);
    \draw [->] (six) |- ([xshift = 0cm, yshift = -5.65cm].northwest) -- (sev);
    \draw [->] 
      (sev) edge (eight)
      (eight) edge (nine);
    \draw [->, dashed] (six) |- ([xshift = 0cm, yshift = -5.075cm].northwest) -- (four);
\end{tikzpicture}

```

## Imputation 

### Original Data Set

The data utilized by this study is the same as the Neumann (CITE Neumann) study and build upond the Leiby (CITE) and Shallcross (CITE) studies. The data initially consisted of 182 countries from the Neumann, Leiby, and Shallcross studies from the 2004-2014 and the same independent variables analyzed by the Neumann's research. This study still imputed and used the Military Expenditure as a percent of government spending despite Neumann (CITE) removing from her work because of a high percentage of the variable being unobserved. This research added the same two additional technology variables, two derived border conflcit variables inspired by the Leiby (CITE) research, and dependent conflict transition variable as the Neumann (CITE) study. These generated variables are explained in further detail after the missing data observations were first imputed.

### Missing Data

This study assumed that all of the unobserved data is missing at random. This means that probability of being missing is not the same for all cases but within that group of data's observed values (CITE Buuren). The probability that a data point is missing only depends on observed data values and not any unobserved or outside it's group. Assuming the data is missing at random is the foundation for this research's applied imputation methods. The original data was missing observations for 21 of the 32 variables over the past ten years. The missing observations accounted for about 6.79\% of the data's total observations. After splitting the data by region, the missingness per region ranged between 3.22\% and 9.05\% of the entire regions observations. 

Before applying more complex imputation methods, the variable Polity IV's missing observations were filled using information provided by the fully observed Regime Type variable. Goldstone's CIA study created the Regime Type variable as an indicator of political instability (CITE Neumann #7). Regime type originally had 57 descriptors of a country's government, and Boekstein simplified the variable down to just a three level indicator (CITE Neumann #15). Regime type is observable and constant each year for every country analyzed in this study. The Polity IV is an integer variable ranging from -10 to 10 where a -10 means a country's government is fully autocratic and 10 fully democratic. Specific Polity IV indicators were given to those country's with anarchies, transitioning governments, or governments experiencing a foreign interruption. The missing observations for Polity IV were filled based on the Regime Type of a country using the mapping of the three levels of Regime Type as seen in Table XX.

```{r, xtable1, results='asis', eval=TRUE}
library(kableExtra)

Polity.transform <- data.frame(
  "Regime Type" = c("Central Ruling Party",
                  "Emerging, Transitional, Recent Change, and Disputed",
                  "Democratic"),
  'Corresponding Polity Value'   = c('-10','0','10')
)

#kableExtra::kable(text_tbl, "latex", booktabs = T) %>%
#  kable_styling(position = "center")
methods_table <- xtable::xtable(Polity.transform, caption = 'Mapping of Regime Type to Fill Missing Polity Values', label = 'table:polity.tranform', align = "llc")
print(methods_table, comment = F, include.rownames=FALSE, scalebox = 0.9, sanitize.text.function = function(x){x}, table.placement = "H")

```

Neumann's (CITE) research identified new groups of countries based on applying Modified K-Means Algorithm to the 2014 data for the selected 182 countries. The groupings found came from the algorithm's similiarities between data and location. Neumann's new groupings are how this study breaks down the 182 countries of interest, and her new COCOM 1 and 6 are the primary regions analyzed by this study. New COCOM 1 and 6 contain countries with historically violile conflict statuses which makes them of greater interest for analyzing future conflict transitions. 

### Mulitple Imputation by Chained Equations

Multiple imputation by chained equations (MICE) was the method used to impute the remaining missing observations. The MICE package in R allowed this method to be applied to each multivariate data set of Neumann's six world regions (CITE Mice R Package). Multiple imputation creates _m_ > 1 complete versions of the data by filling the missing observations with plausible data values (CITE Buuren). Using multiple imputed data sets helps address the statistical uncertainity involved with impututing data. The MICE algorithm is a fully conditional specification imputation method which means it imputes multivariate missing data in a variable-by-variable manner (CITE Buuren). MICE predicts a column of missing data as a the target variable in a regression equation with the all the other variables as the predictors unless other specified (CITE R MICE package). If a predictor is missing an observation, then the most recent iteration's imputation value is used to impute the target variable (CITE MICE package). MICE is a Markov chain Monte Carlo method in which the state space consists of of all imputed values. The MICE algorithm must satisfy three properties to converge, just as any Markov chain would converge to a stationary distribution.

  * irreducible, the chain must be able to reach all interesting parts of the state space
  * aperiodic, the chain should not oscillate between different staes
  * recurrence, all inresting parts can be reached infinitely often at least from almost all starting points
  
The first step in filling in the initial missing data observations was checking to see if the MICE algorithm was converging for each region. Van Burren identified there being no clear-cut method for determining whether the MICE algorithm has converged but that suitable imputations can be spotted from plotting one or more parameters versus the iteration number. The means and standard deviations were plotted for each variable's imputation streams. Healthy converges were categorized by freely intermingled different streams, without showing any trends and the variance between different sequences not being larger than the variance within each individual sequence. Below are an example of a healthy convergence when imputing freshwater per capita in South East Asia. 

```{r healthy convergence, eval = TRUE, fig.cap = 'Healhty-Convergence of the MICE Algorithm for Freshwater per Capita in South East Asia',echo=FALSE}
load("C:/Users/ZKane/OneDrive/Documents/KaneThesis/healthy_convergence.RData")

```

After looking at MICE applied to this analysis's data and seeing previous research's MICE convergences, around 20 iterations there was sufficient convergence by the algorithm. Moving forward each imputation conducted was run for 20 iterations. MICE allows for several different imputation techniques to be specifically applied to each variable every pass. _m_ of these chains are calculated in parallel, and after around 15-20 iterations for one regression chain, the regression coefficents for each missing variables' models are likely to converge (CITE burren page 116). MICE utilizes the columns of fully observed data in these chains. Imputing with a subset of only the missing data or simplified data set may deprive the MICE algorithm of information from the observed data. For this reason, each imputation was performed with the missing and complete columns of data. Multiple imputation procedurely will impute the data, analyze each imputed data set seperately, and pool the results. The intital imputation began with investigating which MICE method resulted in the data most similiar to the distribution of observed data. The five mice packages tested are shown in Table XX. 

```{r, xtable2, results='asis', eval=TRUE}
library(kableExtra)

imp_methods <- data.frame(
  Method = c("cart", "pmm", "norm", "rf", "mean"),
  Description = c(
    "Classification and regression trees",
    "Predictive mean matching",
    "Bayesian linear regression",
    "Random forrest",
    "Unconditional mean imputation"
  )
)

#kableExtra::kable(text_tbl, "latex", booktabs = T) %>%
#  kable_styling(position = "center")
methods_table <- xtable::xtable(imp_methods, caption = 'Imputation Methods Tested', label = 'table:imp_methods_tested')
print(methods_table, comment = F, include.rownames=FALSE, scalebox = 0.9, sanitize.text.function = function(x){x}, table.placement = "H")
```

Between all of the six regions, there were average about 12 variables per region that required imputation by MICE. MICE has the ability to impute and utilize categorical varibales. MICE creates dummy variables for the categorical variables and generates their regressions and resulting imputations from these (CITE MICE R package). None of the variables requiring imputation were categorical, but there were categorical various such as Regime Type that were included in the prediction of other missing variables. The MICE imputation methods investigated were selected based on there not any missing categorical variables and trying to test a wide variety of methods. Imputation using classification and regression trees (CART) seek predictors and cut points in the predictors used to divide up the sample of data. The data is split up repeatidly until a binary tree is build to determine the target variable (CITE Van Buuren). CART methods for imputation are robust against outliers, can handle multicollinearity and skewed distributions, and are able to fit interations and nonlinear relationships (CITE Van Buuren). Predictive mean matching (pmm) is an imputation technique which utilizes the observed data to calculate the predicted target value. It takes a random draw from the candidate donors from the complete cases with predicted values closest to the predicted missing entry value (CITE Van Buuren). The norm method applies Bayesian linear regression that uses parameter uncertainty from random draws from a posterior probability distribution based on the observed data (CITE Van Buuren). 

### Testing Imputation Methods

Each of the five MICE methods were run to develop five different imputed data sets per region and then compared using the Kolmogorov-Smirnov (K-S) and non-parametric, 2-sample Anderson-Darling (A-D) tests. The K-S test looks at if the imputed data values are similiar to the observed data values. This test makes the assumption that the imputed data should follow the same distribution as the observed data (CITE Abayomi, Brantley #36). Engmann and Cousineau (CITE Brantley 37) compared both the A-D and K-S tests and found that the A-D performed better when analzying moments and small differences in the tails of distributions. Based on these findings, the A-D test for this analysis will be the main differentitor between imputation methods (CITE Brantely). The null hypothesis behind both of these tests is that the distributions come from the same parent distribution. A small p value indicates that the imputed data and original data are significantly different and can be interepreted as a poor imputation method. For some variables missing a high percentage of observations such as Freshwater per Capita which was missing for ~74\% of observations, no imputation method was able to find a statistical similarity between that method's imputed data and the observed data.

In some literature the mean absolute error and root mean square error have been used to assess the performance of an imputation method. This analysis didn't utilize these measures of accuracy based on the difference between true and the imputed data. Due to there being so few complete cases for certain variables, evaluation metrics that were based on knowing the true values for missing data weren't implemented. Van Buuren also detailed the shortcomings of treating imputation as a prediction problem geared towards finding the best value. The goal of multiple imputations is "to obtain statistically valid infrences from incomplete data" (CITE Van Buuren). Also treating imputations as methods to enhance the classification accuracy may favor strange imputation methods (CITE Van Buuren). For these reasons, evaluating and choosing an imputation method becomes an increasingly complex problem. Van Buuren's warning as well as the conflicting results and ties between the K-S and A-D statisitical tests begged for another imputation evaluation metric to decide the optimal method. Diagnostic graphs were implemented lastly to asses the plausibility of each imputation method: box and whisker plot and kernel density plots. The box and whisker plot was chosen over strip plots based on Van Buuren's recommendation that the box and whisker plot is more appropriate for large data sets. Both these plots compare the discrepancyies between the observed and imputed data. Dramatic differences would signify a possibility that something with the imputed data needed further investigating (CITE Van Buuren). The diagnostic plots were used to validate the results of the A-D and K-S tests as well as break any potential ties from seeing which imputed values from a given are more reasonable. For example the variable freshwater per capita from the Arab region had all five inputed values insignificantly different from the observed data when tested using the A-D and K-S tests. The box and whisker plots and density plots were then examined to learn more differences between imputation techniques. A suitable imputation technique would produce values that could be observed if the data had not been missing at all (Cite MICE Article page 42). The best performing plots had imputed data visually closest to the observed data. The diagnostic plots After applying applying the K-S and A-D statistical tests and inspecting the diagnostic plots, the imputation methods were decided for each variable in a given region. 

```{r, xtable3, results='asis', eval=TRUE, cache=TRUE}
load("C:/Users/ZKane/OneDrive/Documents/KaneThesis/completed_SE_asia.RData")
load("C:/Users/ZKane/OneDrive/Documents/KaneThesis/completed_arab_imp.RData")
load("C:/Users/ZKane/OneDrive/Documents/KaneThesis/SE_Asia_Mobile_imp.RData")

methods_SE_asia <- data.frame(jm_SE_asia$method[which(jm_SE_asia$method != "")])
methods_arab <- data.frame(jm_arab$method[which(jm_arab$method != "")])
methods_SE_asia_mobile <- data.frame(jm_SE_asia_Mobile_Cells$method["Mobile.Cell.Subs"])
names(methods_SE_asia_mobile) <- names(methods_SE_asia)
methods_SE_asia <- rbind(methods_SE_asia,methods_SE_asia_mobile)

library(data.table)
methods_arab <- setDT(methods_arab, keep.rownames = TRUE)[]
methods_SE_asia <- setDT(methods_SE_asia, keep.rownames = TRUE)[]
methods_SE_asia_mobile <- setDT(methods_SE_asia_mobile, keep.rownames = TRUE)[]
methods <- merge(methods_arab, methods_SE_asia, by = "rn", all = TRUE)
colnames(methods) <- c("Variable", "Arab", "South East Asia")
library(xtable)

xtd2 <- xtable::xtable(methods, caption = 'Imputation Methods Used for Each Variable by Region',
                       align = "llcc", label = 'table:imp_methods')
print(xtd2, comment = F, include.rownames=FALSE, scalebox = 0.8,
      sanitize.text.function = function(x){x}, table.placement = "H")
```

### Imputation Challenges

A problem that aross specifically with the South East Asia region is some variables are linearly related. When the MICE algorithm builds the regression equation to predict a missing value, a variable that is a linear combination of another will result in a singularity error that breaks the MICE algorithm. To fix this, the redundent variables must be excluded from the set of predictor variables used by MICE. The dependent variables can be identified by the last eigenvector of the covariance matrix of the data after performing listwise deletion. The variable Mobile Cell Subscriptions was highly correlated ($>0.5$) with multiple variables. Mobile Cell Subscriptions by far had the smallest loading ($2.012761e-11$) on the on the last eigenvector of the covariance matrix. For these reasons Mobile Cell Subscriptions was imputed individually using the MICE algorithm. When removed the singularity errors ceased to disrupt the MICE algorithm.  

## Regression Models

With the complete data from the previous ten years since 2014, linear regression models were built for each variable of interest. Neumann's model's for regions in and out of conflict defined the variable that would be of interest for this research. The variables required in Neumann's models will be required to predict future conflict transitions. The regression equations define each variable to be explained by the rest of the data. Each regression model was built with the goal of achieving the most parsimonium model from the other variables in the data. Before the regression models were build and reduced, the data set required certain variables gereated by Neumann's research be developed using the complete data. Van Buuren stressed the importance of developing imputations before any additional variables are generated (CITE Van Buuren). Additionally certain variables that are derived from the rest of the data didn't require regressions to be build since their values in future scearios can be calculated then. 

### Variable Development

After filling all the missing gaps in the data, variables of interested were developed to match the data set of previous works such as Neumann and Shallcross. A Government variable was created based on the values of the Polity variarble to indicate a nation's government type. The six categories of this variable are shown in Table \@ref(tab:govmapping).

```{r govmapping, xtable, results='asis', eval=TRUE}

Government_mapping <- data.frame(
  '1' = c("-10 to -6", "-5 to 5", "6 to 10", "-66", "-77", "-88"),
  '2' = c('0','1','2','3','4','5'),
  '3' = c("Autocratic",
                         "Emerging Democracy",
                         "Democratic",
                         "Foreign Interruption",
                         "Anarchy",
                         "Transitional")
)

#KableExtra::kable(Government_mapping, "latex", booktabs = T) %>%
#  kable_styling(position = "center")
government_table <- xtable::xtable(Government_mapping, caption = 'Goverment Type Mapping from Polity', label = 'tab:gov_mapping', align = "cccc")
names(government_table) <- c("Original Polity Value", "Government Type Number",
                             "Government Type")
print(government_table, comment = F, include.rownames=FALSE, scalebox = 0.9,
      sanitize.text.function = function(x){x}, table.placement = "H"
      )

```

The Percent Border Conflict is consistent with the percent border conflict variable in Neumann (CITE Neumann) and border conflict variable in Shallcross (CITE Shallcross) and Boekestein (CITE BOEK). The Percent Border Conflict is calculated by summing the product of all the percentages neighboring country border a country of interest and the neighboring countries HIIK level of conflict intensity for a given year. Islands were assumed to have no neighboring countries and a zero Percent Border Conflict. Equation XX defines the Percent Border Conflict Variable 
\begin{gather}
PctBC_{ij} = \sum_{k=1}^{n} H_{kj}p_{k} \text{where} \nonumber\\
n = \text{number of bordering countries for country $i$} \nonumber\\
H_{kj} = \text{HIIK conflict intensity level for country $k$ in year $j$} \nonumber\\
p_{k} = \text{percent of border country $i$ shares with county $k$} \\
i = \text{Country} \in \{1,2, ..., 182\} \nonumber\\
j = \text{Year} \in \{2004, ..., 2015\} \nonumber\\
k = \text{Bordering country} \nonumber
\end{gather}

The Average Border Conflict measures the average conflict intensity around a given country in a given year and is consistent with Neumann's (CITE Neumann) average border conflict variable. Islands are treated as having no bordering countries. The calculation for the Average Border Conflict is defined by Equation XX. 
\begin{gather}
AvgBC_{ij} = \frac{\sum_{k=1}^{n} H_{kj}}{n} \text{where} \nonumber\\
n = \text{number of bordering countries for country $i$} \nonumber\\
H_{kj} = \text{HIIK conflict intensity level for country $k$ in year $j$} \\
i = \text{Country} \in \{1,2, ..., 182\} \nonumber\\
j = \text{Year} \in \{2004, ..., 2015\} \nonumber\\
k = \text{Bordering country} \nonumber
\end{gather}

The Binary Border Conflict variable is consistent with the binary border conflict variable in both the Neumann (CITE Neumann) and Leiby (CITE Leiby) studies. It is a binary representation for a given country if one of their neighboring nations meets a certain conflict intensity in a given year. Islands are again assumed to have a zero score as they are not neighbored by any nations. Binary Border Conflict score is defined for a given country by Equation XX.
\begin{gather}
BinBC_{ij} = 
  \begin{cases}
    1 & \quad \text{if $H_{kj} \ge 3$ for any country bordering country $i$} \\
    0 & \quad \text{otherwise}
  \end{cases}
\nonumber\\
H_{kj} = \text{HIIK conflict intensity level for country $k$ in year $j$} \\
i = \text{Country} \in \{1,2, ..., 182\} \nonumber\\
j = \text{Year} \in \{2004, ..., 2015\} \nonumber\\
k = \text{Bordering country} \nonumber
\end{gather}

The dependent variable, Conflict Transition, is a binary representation if a country has changed conflict status since the previous year. Conflcit status is defined by the mapping a country's HIIK conflict intensity level in a given year. HIIK scores of 0, 1, and 2 are mapped to a 0 for the conflict status and indicate a country is not in conflict that year. HIIK scores of 3, 4, and 5 are mapped to a conflict status of 1 and represent a country is in state of conflict in that given year. The Conflict Transition binary variable for a country in a given year depends on the current and previous years conflict status. Conflict Transition is equal to 1 if the conflict status of a given year _i_ is not equal to the conflict status of the previous year _i-1_. Table XX below represents this mapping from conflict status for years _i-1_ and _i_ to the binary Conflict Transition variable in year _i_. 

```{r conflicttransitionmapping, xtable, results='asis', eval=TRUE}

conflict_transition <- data.frame(
  '1' = c("0 = Not In Conflict", "1 = In Conflict","0 = Not In Conflict", "1 = In Conflict"),
  '2' = c("0 = Not In Conflict", "1 = In Conflict","1 = In Conflict","0 = Not In Conflict"),
  '3' = c("0 = Not In Conflict", "0 = Not In Conflict","1 = In Conflict","1 = In Conflict")
)

#KableExtra::kable(Government_mapping, "latex", booktabs = T) %>%
#  kable_styling(position = "center")
conflict_transition_map <- xtable::xtable(conflict_transition, caption = 'Mapping of Conflict Transition', label = 'tab:conflict_transition_mapping', align = "ll|l|l")
names(conflict_transition_map) <- c("Conflict Status Yr $i-1$", "Conflict Status Yr $i$",
                             "Conflict Transition Yr $i$")
bold <- function(x) {paste('{\\textbf{',x,'}}', sep ='')}
print(conflict_transition_map, comment = F, include.rownames=FALSE, scalebox = 0.9,
      sanitize.text.function = function(x){x}, table.placement = "H", hline.after = c(-1,0,2,nrow(conflict_transition_map)),
      sanitize.colnames.function = bold, booktabs = T
      )

```

### Model Building Procedure

Linear regression models were build for variables that were significant in Neumann's logisitic regression models that predict a country's Conflict Transition. Linear regression models were build to statistically define each individual variable of interest by the other variables in a given region. Testing was completed to include higher order terms and interaction terms in these models, but due to the higher achieved adjusted $R^2$ values, models were only build using the main effects. The complete data set used to build the models consists of all five of the imputed data sets stacked on top of each other. This goes against Van Buuren's advice to pool the resulting models, but due to the desire for point estimates defining each variable of interest, the simplier method of stacking the imputations was preferred. With less than $10\%$ of the observations missing from the two new world regions of interest, the research is impacted less from weight of the missing data. The stacked imputed data results in _m_ x _n_ complete records where _m_ still being the number of imputed data sets. The statistical analysis thus becomes a weighted linear regression with a weighted factor of $1/m$ applied to each record. Having low levels of missingness and the point estimates generated from the stacked complete data being unbiased (CITE page 158) makes treating the imputed data as a stacked, long data set sufficient for the purposes of this research.

Stepwise regression is the primary method used to generate parsimonous linear regression models for each variable. This method iteratively removes predictor variables while computing a linear regression model each time. Each time a regression is rerun, each predictor variable's associated p value is assessed to see if it is within a specified acceptable range. By deleting variables from the model, the precision of point estimates of the remaining in the model are improved (CITE intro to linear). The stepwise method was run using JMP with chosen p value for entering and removing a variable of 0.05. Stepwise regression operates in a direction to either enter or remove a term with the smallest or largest p value. The mixed option in JMP alternates between a forward and backward selection to include the only significant terms. Models were building stepping from a null and full model using the mixed selection method. Most times the reduced models were the same, but if there were any differences, the model that achieved the higher $R^2_{adj}$ was chosen. The coefficient of multiple determination, $R^2$, is a measure of model adequacy that represents the proportion of variance explained by the regression. Adding regressors to the model will improve $R^2$ but can still produce a worse model and larger error mean square by losing one degree of freedom for error (CITE intro). A low value of $R^2$ for this research indicates a poorly specified model (CITE intro). $R^2$ will never decrease from adding a variable to the model, so it is important in varaibel selection to include another evaluation statistic. $R^2_{adj}$ will only improve if the variable added reduces the residual mean square to prevent overfitting (CITE intro). This research will reference to $R^2_{adj}$ when evaulating models in stepwise regression. Interaction terms were also selectively included in models with lacking $R^2_{adj}$ (<0.5). In an effort to devleop parsimonious models, only second order interaction terms were considered. With the interactions factored into the model, the Arab region produced 74 possible variables while there were 209 possible variables in the SE Asia region. Stepwise regression reduced these numbers for the models requiring higher $R^2_{adj}$. All of the Arab region models were built with interactions, but only Population Growth's interactions were necessary in South East Asia.
  
### Assessing Model Adequacy

The final stepwise models were analyzed to ensure they met all the assumptions of linear regression. Linear Regression assumes the error terms or residuals must be independent, normal, and random variables with mean of $0$ and constant variance $\sigma^2$ (CITE data mining and analysis). Graphically, these linear regression assumptions can be evaluated using a normal probability plot of the residuals and a plot of the standardized residuals against the predicted values. A normal probability plot of the residuals is a quantile-quantile plot where quantiles of a particular distribution are plotted against the quantiles of the standard normal distribution to identify deviations from normality (CITE data mining). If a distribution is normal then a majority of the points in the graph should fall close to the diagonal reference line. Statistically, there are lot of different ways to test normality with each depending on the data at hand. The deviations from normality were calculated using the Cramer-Von Mises test where the null hypothesis is that the distribution of the errors follows a normal distrubition. It is a simplified version of the Anderson-Darling test that does not provide as much weight to the tails of the distribution. It is not the most powerful empirical distribution test, but this research choose to have more relaxed normality standards to avoid conducted more in depth outlier analysis and accept simplier models sooner. The Cramer-Von Mises statistic is calculated as,
\begin{gather}
CVM = \frac{1}{12n} + \sum_{i=1}^{n} [F_0(x_{(i)})-\frac{2i-1}{2n}]^2
\end{gather}
where $n$ is the sample size and $x_i$'s are the ordered data (CITE CVM). P value scores lower than $0.05$ indicate a regression model's errors don't follow a normally distrbuted. The package oslrr (CITE olsrr) in R was used to test the normality of each variable of interests' residuals.

A plot of the standardized residuals against the predicted values helps identify patterns in the variance of a model's residuals. Linear regression assumes homoscedasticity, constant variance, and independence of a model's error term. These plots tests both of these assumptions and should not represent any clear funnel, linear, or u-shaped pattern. If the variance of the errors is increasing or decreasing over time, confidence intervals for new predictions will tend to be unrealistic (CITE DUKE). The plots should be evenly spread out and distanced from the x-axis (CITE data mining). Statistically, these assumptions are tested using the Breusch Pagan test for homogenity of variances from the olsrr package (CITE olsrr) in R where the null hypothesis is that the variance is constant based on a chi-squared test. This test sees whether the variance of the errors from a regression is dependent on the values of the independent variables (CITE cran heter). Below in Table XX the final models' adequacy tests can be found and any respective transformations.

```{r modeladeqarab, xtable, results='asis', eval=TRUE}

load("C:/Users/ZKane/OneDrive/Documents/KaneThesis/Arab_reg_table.Rda")
load("C:/Users/ZKane/OneDrive/Documents/KaneThesis/SE_Asia_reg_table.Rda")
reg_table <- rbind (Arab_reg_table, SE_Asia_reg_table)
reg_table[c(2,4,6,8:10,12,13),5] <- "<0.0001"
reg_map <- xtable::xtable(reg_table, caption = 'Regression Model Adequacy Check', label = 'tab:reg_models', align = "lcccccc", digits=c(0,4,4,4,4,4,4))

names(reg_map) <- c("$R^2$", "$R^2_{adj}$", "F-Test",
                             "Cramer-Von Mises", "Normality", "Transformation")
rownames(reg_map) <- c("Arab Mobile Cell Subscriptions","Arab Population Density","Arab Percent Border Conflict","Arab Fertility Rate","Arab Trade Percent GDP","SE Asia Internet Users","SE Asia Life Expectancy","SE Asia Mobile Cell Subs","SE Infant Mortality Rate","SE Asia Population Growth","SE Asia Arable Lands","SE Asia Avg Border Conflict", "SE Asia Freshwater per Capita")
#bold <- function(x) {paste('{\\textbf{',x,'}}', sep ='')}
print(reg_map, comment = F, scalebox = 0.75,
      sanitize.text.function = function(x){x}, table.placement = "H",
      booktabs = T, include.rownames = TRUE
      )

```

### Transformations

Certain variables regression models were improved after the dependent variarbles were transformed. These transformations were performed to possible improved the model's $R^2_{adj}$, normality, or homoscedasticity statistics. If a transformation tested raised any of these categories, then the transformation was made for model from here on out. The square root was taken for the Population Density variable in the Arab region ($\sqrt{Population Density}$). The transformation improved a higher $R^2_{adj}$ but didn't improve the model's homoscedasticity or nomarlity violations. The log was taken of a few variables which helped some of those models to fulfill the linear regression assumptions ($log(y_i)=\beta_0+\beta_{1}x_{1i}+...+\beta_kx_{ki}+e_i$). Mobile Cell Subscriptions in the South East Asia region was transformed initally just by the square root, but the model continued to improve further by then taking the fourth root ($\sqrt[4]{Mobile Cell Subscriptions}$). JMP offered other transformations that were tested but didn't out perform the three ones (log, square root, and fourth root) that were actually done. 

Even after the transformations were added, the regression models didn't statistically meet all of the assumptions of linear regression. This research recognizes the discrepencies in the models, but accepts the models, and will proceed with them for developing future alternatives of world conflict. 

## Alternative Future Generation 

With the data properly imputed and regression models built for each variable of interest, the alternative futures were developed. An iterative explanatory approach inspired by univariate imputation techniques was the primary approach to generating the complete future data sets. For each region individually, Neumann's conflict prediction models were applied each year to see find a probability of a country transitioning in or out of a state of conflict. Each variable value would be calculated using the previous years values using the regression equations created based on the other variables of interest in their respective region. To improve on the predicted value of these equations, random noise was added to the predicted value. This noise introduces variability that reflects the inherent inaccuracy associated with predicting variables from an insufficient subset of variables. Van Buuren (CITE) injects noise from a random draw from the normal distribution based on the assumption that the observed data is normally distributed around the regression line. Due to the regression equations largely violating this assumption, the noise instead came from a random draw from the residuals of the variables' regression equations. Before Neumann's conflict transition logistic regressions could be applied, the complete predicted data for the next year were assessed for operational feasibility. This varied by region and variable, but the variables' values were restricted as to not exceed two times the region's largest value and one half of the region's smallest value recorded in the last ten years. These conservative limits placed on the prediction values plus the noise elliminated variables reaching inconceivable highs or lows and maintained the operational relevancy of this research. 

Certain variables identified as signficant to predicting conflict transitioning were calculated based on the new variables' values rather than by their own regression equations with noise or were assumed not to be changing over the years. The two year conflict intensity trend of a country was calculated manually based on the previous year's HIIK conflict intensity score minus the country's HIIK conflict intensity score from two years ago all divided by six for the six different HIIK levels. The regime and government type variables were assumed not to change year to year because they are binary indicators of levels ranging from autocracy to democracy for a nation which for this research's purposes wouldn't change over the years of focus. A country's government type is considered a hard to change factor, so the iterative forecast method treated a nation's government as constant through the course of any conflict transitions. The HIIK conflict intensity level each year was calculated based on the probability that a nation would transition in or out of conflict. The new year's data would be plugged into Neumann's logistic regression equations depending on the conflict status of the previous year. From there the predicted value of the logisitic regression would be converted into a probability. Recall that the formula for a logistic regression function is as follows.

\begin{equation}
ln(\frac{p}{1-p})=\beta_0+\beta_1x_1+...+\beta_nx_n
\end{equation}

The formula for logistic regression contains p, the probability and n, the number of variables. To solve for p, the exponential of the predicted value of logistic regression was divided by one plus the same exponential of the predicted value from the logistic regression. 
 
\begin{equation}
p=\frac{exp(\beta_0+\beta_1x_1+...+\beta_nx_n)}{1+exp(\beta_0+\beta_1x_1+...+\beta_nx_n)}
\end{equation}

A higher probability indicates that a nation has a higher chance of transitioning conflict statuses while a smaller probability means a country's conflict status will remain at the same level of conflict for that year. A 0.5 probability cutoff was used to decided which direction a country would transition: transition or stationary. A random draw was taken between 0 and 1 to compare to the calculated transition probability. The random draw comparison represents the uncertainty that given a country's probability to transition conflict status, a country may not actually transition in the direction the logistic regression equations found to have the highest probability. If the random draw, in the direction of transition or remaining the same exceeds the logistic regression equation's probability of conflict transition than the country's conflict will in fact not do what it has the highest probability of doing. For example, if a country was in conflict last year and the in conflict equation for that region found a transition probability of 0.91, the country is likely to transition to being out of conflict. A random draw would be taken between 0 and 1, and say the random draw was 0.95, than due to the random draw exceeding the transition probability in the likely transition direction, than the country would remain in conflict. 

HIIK conflict intensity was mapped each year based on the conflict transition probability and random draw comparison. If a country, after taking and comparing the random draw, transitions in the direction indicated by the transition probability than the HIIK conflict intensity was just mapped following the below mapping. 

```{r in_HIIKmapping, xtable, results='asis', eval=TRUE}

in_conflict_HIIK_transition <- data.frame(
  '1' = c("Transition and Does", "", "",
          "Transition and Doesn't",
          "Remain and Does", "", "",
          "Remain and Doesn't"),
  '2' = c("Not In Conflict", "", "",
          "In Conflict", 
          "In Conflict",  "", "",
          "Not In Conflict"),
  '3' = c("(1-$5/6$) = 0", "($5/6$-$4/6$) = 1", "($4/6$-$3/6$) = 2",
          "3", 
          "($3/6$-$2/6$) = 3", "($2/6$-$1/6$) = 4", "($1/6$-0) = 5",
          "2")
)


in_HIIK_map <- xtable::xtable(in_conflict_HIIK_transition, caption = 'Previous Year In Conflict Mapping HIIK Conflict Intensity ', label = 'tab:in_HIIK_mapping', align = "ll|c|c")
names(in_HIIK_map) <- c("Random Draw Comparison",
                                    "Conflict Status Year $i$", "Year $i$ HIIK Mapping")
bold <- function(x) {paste('{\\textbf{',x,'}}', sep ='')}
print(in_HIIK_map, comment = F, include.rownames=FALSE, scalebox = 0.75,
      sanitize.text.function = function(x){x}, table.placement = "H", hline.after = c(-1,0,3,4,7,nrow(in_HIIK_map)),
      sanitize.colnames.function = bold, booktabs = T
      )

```

For a country that was in conflict the previous year, the random draw comparison column reads transition when the transition probability calculated using Nuemann's in conflict logistic regression equations yield a probability over 0.5. If the random draw is larger than the transition probability, the column will read transition and doesn't. Since the country's conflict is behaving contradictory to how the equations predict, the HIIK conflict intensity is mapped to being the lowest in conflict score of 3. Otherwise, the column reads transition and does, meaning the country for that year transitions to not in conflict and it's HIIK conflict intensity is inversly mapped based on an even division between 0.5 and 1 for the out of conflict HIIK conflict intensity scores. The same approach is taken when a country in conflict is supposed to stay in conflict (transition probability < 0.5) except now the country will only do the opposite of the predicted transition probability if the random draw is less than the transition probability. In the case that the random draw is that small and the country doesn't stay in conflict, HIIK conflict intensity is set as the lowest not in conflict score of 2. When the previously in conflict country should remain in conflict and does, the transition probability is directly mapped to the top three HIIK in conflict scores based on an even division of 0.5 to 0 as seen above. The proceeding mapping of a country that was not in conflict the previous year is mapped in the same manor but with some of the mappings flipped accordingly. 

```{r out_HIIKmapping, xtable, results='asis', eval=TRUE}

out_conflict_HIIK_transition <- data.frame(
  '1' = c("Transition and Does", "", "",
          "Transition and Doesn't",
          "Remain and Does", "", "",
          "Remain and Doesn't"),
  '2' = c("In Conflict", "", "",
          "Not In Conflict", 
          "Not In Conflict",  "", "",
          "In Conflict"),
  '3' = c("(1-$5/6$) = 5", "($5/6$-$4/6$) = 4", "($4/6$-$3/6$) = 3",
          "2", 
          "($3/6$-$2/6$) = 2", "($2/6$-$1/6$) = 1", "($1/6$-0) = 0",
          "3")
)

out_HIIK_map <- xtable::xtable(out_conflict_HIIK_transition, caption = 'Previous Year Not In Conflict Mapping HIIK Conflict Intensity ', label = 'tab:out_HIIK_mapping', align = "ll|c|c")
names(out_HIIK_map) <- c("Random Draw Comparison",
                                    "Conflict Status Year $i$", "Year $i$ HIIK Mapping")
bold <- function(x) {paste('{\\textbf{',x,'}}', sep ='')}
print(out_HIIK_map, comment = F, include.rownames=FALSE, scalebox = 0.75,
      sanitize.text.function = function(x){x}, table.placement = "H", hline.after = c(-1,0,3,4,7,nrow(out_HIIK_map)),
      sanitize.colnames.function = bold, booktabs = T
      )

```

HIIK conflict intensity was an important variable to map as it was included in multipe variables' explanatory regression equations previously built. It depends on the conflict status of a country, so it was calculated iteratively each year after the transition probability equations were already applied.With the HIIK conflict properly mapped and conflict transition logic developed, alternative futures were generated based on the trends from each variables' regression equations.

### Regional Scenarios

The alternative futures created from unrestricted flow of the data into the future based on their individual regression equations was modified by scenarios a region may possibly face. These scenarios were implemented by manipulating how a certain variable behaves in the projected future yearly observations. Each region, having different predictive conflict models, was subject to slightly different variable trends in order to test a certain scenario. The three conflict what if scenarios that were tested were as follows. 

1. Does peace beget peace?
2. Is democracy the most peaceful form of governance?
3. How does trade impact the conflict environment of a region?

Answering each of these questions differed between the two regions of focus. For the Arab nations, the first questions was tested simply by forcing the future years of projected percent of border conflict to be zero. The idea behind this trend is that how will nation's conflict changing depending on if their neighboring nations become nonviolent for the foreseeable future. Does peace surrounding nations in this region permeate across borders. The second questions was aimed to understand the impact that a democratic form of government would have on a nation's conflict status and transitioning. The categorical variable government type used in the Neumann `r citep(BIB[key="neumann"])`, Shallcross `r citep(BIB[key="shallcross"])`, and Leiby `r citep(BIB[key="leiby"])` studies which in this case represented a government type to be an emerging democracy. This was the closest variable in the Neumann  `r citep(BIB[key="neumann"])` logistic regression model which indicated a nation being democratic. 

The first question in the South East Asian region was addressed by manipulating the binary indicator of border conflict and average border conflict for a nation. The binary border conflict indicator was forced to zero for the proceeding sixteen years of projected data to represent bordering nations were in conflict (HIIK score greater than three). The average border conflict was restricted to not exceed a value of two which meant on average, no bordering nations would enter conflict. The second question's scenario was built by setting every future regime type variable developed by Goldstone `r citep(BIB[key="goldstone"])` to be democracies along with creating a floor for the freedom score variable. Freedom score is calculated by averaging of a nation's civil liberties and political rights created by Boekestein `r citep(BIB[key="boekestein"])` to model a nationâ€™s political climate and political oppression. This variable relates to government type, so the minimum freedom score was raised to that of the countries in the region with democratic governments to simulate a trend of democratic governance in the region in conjunction with the coded regime type. 

The third question was addressed in the same way for both regions even thought there were vast differences between the regions' trade as a percentage of a nation's GDP. Explained by Boekestein `r citep(BIB[key="boekestein"])`, the variable for trade is calculated from the summation of two World Bank statistics; Imports of goods and services (\% of GDP) added to exports of goods and services (\% of GDP). The question posses the possibility of extreme trade decreases due to isolationistic, self sufficient, uncertain trade behaviors in a region where trade could be disrupted by political instability or outside pressures. The trade variable's maximum capacity was amended to be the minimum historical observed trade that a nation in that region has ever practiced. This limited each nation's trading engagement to test how a scenario of greatly deceased trade may impact a nation's conflicts to come. 

# Analysis and Results

## Overview

This chapter discusses the results and analysis of applying the methodology outlined in Chapter 3. Each variable of interests' regression models are analzyed in Section 4.2. Section 4.3 discusses the results from the purely data driven future alternatives of country conflict transitions. Section 4.3 discusses the specified scenarios and resulting impact on the conflict in the Arab region. Section 4.5 covers the alterternative futures of what if scenarios in the South East Asia grouping of countries.

## Regional Regression Model Evaluation



## Future Alternative Models' Results and Evaluation

The regional, generic imputation style future alternative model was first run with only operational boundaries constraining the values of each variable of interest. The data's relationships and injected noise was able to determine the directions of each nation's future conflict transitions. To evaluate the model's statistically possibility three metrics were calculated for each repition and averaged to understand the differences between future conflict timelines and the observed historic data for a nation as well as compare individual alternative futures. Each evaluation metric was calculated for the past ten years of observed data and future sixteen years of projected conflicts status. The rates of transitions were found over each past or future time period by counting the times a nation transitioned conflict status divided by the number of years in that period. For example, if a nation remained in conflict for the entirity of the projected future years then it would have transitioned zero times over sixteen years. Its rate of transitions for that nation's single future would be zero ($\frac{0}{16}$). The rates of transitions give insight into how closely or off the future alternatives are from the historic rates of conflict beginnings and stoppages in a specific nation. The conflict likelihood was calculated similiarly but just by counting the number of years in conflict divided by the total years in that period of time. By finding the likelihood of each nation's alternative future, comparing the models' conflict likelihoods provides the possibility of that future alternative. Expanding on this idea, the most recent conflict likelihoods were calculated for the three most recent years of observed data and the first three future projected conflict statuses. Comparing the most recent conflict likelihood gives insight into the more recent similiarities and differences that future alternatives predict versus reality. 

The Arab region in the past ten years has experienced 98 violent conflicts across seventeen countries: Algeria,	Bahrain, Egypt, Iraq,	Jordan,	Kuwait,	Lebanon, Libya, Morocco,	Oman,	Qatar,	Saudi Arabia,	Syria,	Tunisia,	United Arab Emirates,	West Bank, and	Yemen. The generic imputation driven forecasting model projected country conflict from 2015 to 2030. The model repeatedly projected future conflict five times to create five individual alternative futures for each country. The average predicited country conflicts across all five futures was 134.2 violent conflicts for the first ten years of future data. The associated minimum and maximum conflicts for a single future's total ten year conflicts were 125 and 145 respectively. Even on the lower end of projected future conflicts, there appears to be a larger estimates of conflicts that the data driven model predicts for the Arab region. The variable behavior that appeared to indicate a tendancy for conflict was low fertility rate, low trade (\% of GDP), high mobile cell subscriptions, high population density, and high percent border conflict. These characteristics seemed common between the countries that experienced longer periods in conflict. One more observation of the data driven model is only one of the five produced alternative futures predicted that Algeria, a country historically in a state of conflict for the past ten years would remain in conflict. The other four futures generally predicted that Algeria would transfer out of conflict right away (2015) for about three to four years and then return to a state of conflict. The average percentage changes for the three future alternative evaluation measures were the rate of transitons increased 15.123\% across all the countries and replications with a standard deviation of 70.591. The conflict likelihood increased an average of 82.716\% with a 172.506 standard deviation from the past ten years of coutry conflict likelihoods. The most recent (three year) conflict likelihood only decreased by 7.451\% with a standard deviation of 43.197. It seems like the closer projected future conflicts didn't deviate too far from the observed recent conlict realities, but the further away the futures were from the observed historical data, the larger the conflict likelihoods and rates of transitions became with wider bounds as well. This is partially the difficult with making predictions on projected future data. There is no guarentee the future will or should look like the past.

The South East Asia regional conflict transition prediciton model was applied to the generically imputation style forecasted dataset. In the past ten years, the South East Asia region has experienced 136 violent conflicts throughout its 28 nations. With the developed alternative futures from letting the data's relationships dictate their own trends over time for five replications, an average of 97.2 violent conflicts were predicted for the first ten years of projected future conflict statuses. There was a minimum of 91 and maximum of 103 violent conflicts predicted by an individual alternate future replication, and interestingly, the same method applied to build a model in a different region outputted a different trend of overall decade conflict trend towards peace. The recognizable variables' behaviors that were common to country's with futures of prolonged non violence were no border conflict, low border conflict, low arable lands, higher freedom scores, and high trade (\% of GDP). Of all the replicated future alternatives, as opposed to the Arab region which observed multiple countrys with zero future rates of transitions meaning they wouldn't change conflict statuses over the course of the future time period, the South East Asia region future data consisted on higher rates of transitions. Only Laos and Tonga experienced an alternative future with extended periods of peace and extremely low rates of transitions. The model compared to the original ten years of observed data in the region on average across all countries and repitions predicted a 104.61\% increase in the rate of transitions with a standard deviation of 121.941. The conflict likelihood for the future of the region only increased by 18.989\% with a standard deviation of 103.105. The most recent conflict likelihood comparison saw a decrease of 38.095\% with an associated standard deviation of 49.546. The South East Asia region overall saw the smallest average percentage change in historic conflict likelihood and was the least close to historic rates of transitions. Although the two regions are significantly different, they both predicted increased average percentage of changes in rate of transitions and conflict likelihood but on average predicted smaller likelihoods of more recent conflict. Both of these results based on the data driven alternative futures models are used as the base line of comparison for the regional questions analyzed in sections 4.2 and 4.3.

## Arab Nations' Regional Scenarios

The three regional scenarios were tested using modified versions of the purely data driven future alternative model. With the previously mentioned scripted behavior of the percentage of border conflicts of a given nation, the first regional scenario was tested to understand the regional impact of peaceful bordering nations. Despite the logical rational that peace besets peace, the results of this regional scenario were an overwhelming majority of countries entering conflict and staying in conflict for the duration of the future sixteen years. The peaceful borders' future alternatives, averaged across all five replications forecasted 184.6 yearly instances of violent conflicts in countries over the first ten future years. This was over double of the 98 observed instances of countries in violent conflict for the most recent ten years. The future conflicts with enacted peaceful bordering nations were about 50 conflicts more than the original data driven future conflict predicted. Looking closer into each inividual country, only two countries across all five repitions experience a year not in a state of conflict. Oman, Qatar, and United Arab Emirates entered states of non conflict only within the first three years of future data, and all other countries' conflict statuses were in conflict. The noticable variable trends associated with all of the repeated states of conflict despite supposed peaceful bordering nations were low fertility rates, high population densities, and high mobile cell subsribers. Conflict transitions were influenced only when moderate levels of population density, fertility rate, trade (\% of GDP), and mobile cell subscribers existed. The peace in bordering countries does not appear to bring peace to the Arab nations themselves. Interestingly enough, the peaceful bordering nations lead the alternative futures to be have different average percentage of change from the observerd historical data in the Arab region than the data driven original alternative future model. The peaceful border nations scenario had a negative average 57.243\% change of the rate of transitions, a 118.676\% increase in conflict likelihoods, and the mroe recent conflict transitions increase by 18.824\%. Compared to the purely data driven model, preset peaceful regional predicted greater average percentage changes in each of the three statistics. For the most part, increased peace in bordering Arab countries generated alternative futures of increased violent conflicts and minimal conflict transitions out of conflict. 

The second scenario of complete regional democractic govenrmence show in an improved the overall Arab reginoal conflcit enviroment. There were an average of 130.2 yearly instances of nation's being a state of conflict over the first ten years of projected data. This was a slightly smaller estimate than the data driven model, but the influence of democracies still raised the total number of conflicts compared to the most recent ten years of observed data. There was a smaller standard 



## South East Asia's Regional Scenarios



# Conclusions

## Overall Conclusions



##Implications for Research



##Future Research












