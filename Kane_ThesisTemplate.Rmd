---
title:        "`r DODschools::noTouch('metadata.yml')$document$title`"
designator:   "`r DODschools::noTouch('metadata.yml')$document$designator`"
doctype:      "`r DODschools::noTouch('metadata.yml')$document$type`"
pages:        "`r DODschools::noTouch('metadata.yml')$document$pages`"
abstract:     "`r DODschools::noTouch('metadata.yml')$abstract`"
dedication:   "`r DODschools::noTouch('metadata.yml')$dedication`"
acknowledge:  "`r DODschools::noTouch('metadata.yml')$acknowledgement`"
vita:         "`r DODschools::noTouch('metadata.yml')$vita`"
degree:       "`r DODschools::noTouch('metadata.yml')$degree`"
program:      "`r DODschools::noTouch('metadata.yml')$program`"
distro1:      "`r DODschools::noTouch('metadata.yml')$distro_thesis[1]`"
distro2:      "`r DODschools::noTouch('metadata.yml')$distro_thesis[2]`"
author:
  name:       "`r DODschools::noTouch('metadata.yml')$author$fullname`"
  dept:       "`r DODschools::noTouch('metadata.yml')$author$dept`"
  rank:       "`r DODschools::noTouch('metadata.yml')$author$rank`"
  service:    "`r DODschools::noTouch('metadata.yml')$author$service`"
  prevdegree: "`r DODschools::noTouch('metadata.yml')$author$currentDegree`"
  email:      "`r DODschools::noTouch('metadata.yml')$author$email`"
advisor:
  name:       "`r DODschools::noTouch('metadata.yml')$advisor$name`"
  department: "`r DODschools::noTouch('metadata.yml')$advisor$department`"
  rank:       "`r DODschools::noTouch('metadata.yml')$advisor$rank`"
  service:    "`r DODschools::noTouch('metadata.yml')$advisor$service`"
  degree:     "`r DODschools::noTouch('metadata.yml')$advisor$currentDegree`"
  phone:      "`r DODschools::noTouch('metadata.yml')$advisor$phone`"
  email:      "`r DODschools::noTouch('metadata.yml')$advisor$email`"
reader1:
  name:       "`r DODschools::noTouch('metadata.yml')$reader1$name`"
  department: "`r DODschools::noTouch('metadata.yml')$reader1$dept`"
  rank:       "`r DODschools::noTouch('metadata.yml')$reader1$rank`"
  service:    "`r DODschools::noTouch('metadata.yml')$reader1$service`"
  prevdegree: "`r DODschools::noTouch('metadata.yml')$reader1$currentDegree`"
#reader2:
#  name:       "`r DODschools::noTouch('metadata.yml')$reader2$name`"
#  department: "`r DODschools::noTouch('metadata.yml')$reader2$dept`"
#  rank:       "`r DODschools::noTouch('metadata.yml')$reader2$rank`"
#  service:    "`r DODschools::noTouch('metadata.yml')$reader2$service`"
#  prevdegree: "`r DODschools::noTouch('metadata.yml')$reader2$currentDegree`"
#reader3:
#  name:       "`r DODschools::noTouch('metadata.yml')$reader3$name`"
#  department: "`r DODschools::noTouch('metadata.yml')$reader3$dept`"
#  rank:       "`r DODschools::noTouch('metadata.yml')$reader3$rank`"
#  service:    "`r DODschools::noTouch('metadata.yml')$reader3$service`"
#  prevdegree: "`r DODschools::noTouch('metadata.yml')$reader3$currentDegree`"
sf298name:    "`r DODschools::noTouch('metadata.yml')$author$sf298name`"
contractnum:  "`r DODschools::noTouch('metadata.yml')$sf298$contractnum`"
grantnum:     "`r DODschools::noTouch('metadata.yml')$sf298$grantnum`"
prognum:      "`r DODschools::noTouch('metadata.yml')$sf298$programnum`"
projnum:      "`r DODschools::noTouch('metadata.yml')$sf298$projectnum`"
tasknum:      "`r DODschools::noTouch('metadata.yml')$sf298$tasknum`"
worknum:      "`r DODschools::noTouch('metadata.yml')$sf298$workunitnum`"
keywords:     "`r DODschools::noTouch('metadata.yml')$sf298$keywords`"
sponsor:
  title:    "`r DODschools::noTouch('metadata.yml')$sf298$sponsor$title`"
  subtitle: "`r DODschools::noTouch('metadata.yml')$sf298$sponsor$subtitle`"
  address1: "`r DODschools::noTouch('metadata.yml')$sf298$sponsor$address1`"
  address2: "`r DODschools::noTouch('metadata.yml')$sf298$sponsor$address2`"
  phone:    "`r DODschools::noTouch('metadata.yml')$sf298$sponsor$phone`"
  email1:   "`r DODschools::noTouch('metadata.yml')$sf298$sponsor$email1`"
  email2:   "`r DODschools::noTouch('metadata.yml')$sf298$sponsor$email2`"
  acronym:  "`r DODschools::noTouch('metadata.yml')$sf298$sponsor$acronym`"
  rptnum:   "`r DODschools::noTouch('metadata.yml')$sf298$sponsor$report_number`"
graddate:   "`r DODschools::noTouch('metadata.yml')$grad_date`"
date:       "`r format(Sys.Date(), '%B %Y')`"
sf298_date: "`r format(Sys.Date(), '%d-%m-%Y')`"
dissertation: "`r DODschools::noTouch('metadata.yml')$dissertation`"
cite_style: "`r DODschools::noTouch('metadata.yml')$cite_style`"
cite_shape: "`r DODschools::noTouch('metadata.yml')$cite_shape`"
output: 
  DODschools::afit_thesis:
    includes:
      in_header:    scripts/tex/in_header.tex
      before_body:  scripts/tex/before_body.tex
      after_body:   scripts/tex/after_body.tex
---

```{r echo=FALSE, message=FALSE, warning=FALSE}

pacman::p_load(devtools,
               knitcitations,
               RefManageR,
               xtable,
               sas7bdat,
               dplyr,
               survival,
               flexsurv,
               knitr,
               formattable,
               data.table,
               kableExtra,
               survminer,
               gridExtra,
               png,
               grid,
               Gmisc)
source('scripts/R/setup.R')


install_github("Auburngrads/DODschools")

options(knitr.table.format = "latex")
options(kableExtra.latex.load_packages = FALSE)
library(kableExtra)

#source('scripts/R/setup.R')

#BIB <- ReadBib('references/my_bib.bib')
#knitcitations <- BIB[title = 'knitcitations']
#refmanager    <- BIB[title = 'RefManageR']
#pressure      <- BIB[key = 'randolph2016']
#cite_options(citation_format = 'pandoc')
```

# Introduction

## Background

Over the course of human history, the world's countries have continually transitioned in and out of states of internal and foreign conflict. These conflicts range from small unarmed bouts to deadly world wards and have become a major area of study for nations trying to understand and ultimately mitigate the threats brought on by potential conflict and regional instability. The Heidelberg Insititute for International Conflict Research (HIIK) identified 385 conflicts globally in 2017 (CITE). Each nation in a defined state of conflict experienced varying levels of intenisty, nations involved, and influential factors. Due to the uniqueness of each individual conflict, there have been multiple research efforts on building accurate predictive models of armed conflict. Predictive models have incorporated every world conflict to conflict within a single nation. Rooted in a United States military commbatant command approach to grouping nations, predcitive models of country conflict achieved highly accurate results. Recent studies largely focused on finding the most influential variables in predicting the observed data, while this still begs the question of how to predict future data and determine conflicts that will emerge or stagnate. 

This research examines predicting country's conflict based on generated future data of a world region. Future alternatives of a nation's conflict transitions were calculated for two world regions historically stricken with conflict and intially grouped based on location and data similiarity. With a forecasted outline of a region's conflict transtions, a nation's can improve their resource allocation to address a changing future conflict intensities. 

## Problem Statement

Fill the missing observations in the data set utilized by Neumann's research by testing and identifying each variables' optimal imputation method. Develop regression models for the each variable of interest for the two selected world regions. Iteratively create future alternatives for country transitions up to 2030 and solve for each nation's yearly conflict status. Perform region specific what-if analysis to test the robustness region's future conflict alternatives.

## Research Objectives

The objective of this study is to implement the optimal imputation techniques that addresses Neumann's data's missingness by region and to develop future alternatives of country conflict landscape using an interative imputation style explanatory forecasting method. 

## Research Questions

This study seeks to answer the following research questions on the future alternatives of conflict transitions in the Arab and South East Asia regions of the world. 

**Question 1**

How should the data set utilized in the Neumann study be imputed?

**Question 2**

How can we develop regression models for each variable of interest in a given region?

**Question 3**

What insights, nations succeptible or impervious to conflict transitions are identified by the generated regional conflict future alternatives?

**Question 4**

How robust are the future alternatives of conflict tranistions to the what-if analysis scenarios tested for each region?

## Assumptions and Limitations

This study is based on four underlying assumptions. The first assumption, similiar to other conflict prediction research, is that the data analyzed is accurate and describes the commonalities between countries and their conflicts. The geographical groupings by region identified by the Neumann study were assumed to be suitable commonality in terms of economy, geography, ethnic, and religious demographics to develop future alteratives. The third assumption is that the variables identified as significant for Neumann's conflict logitstic regression models are the only relevant variables for predicting conflict during the duration of future years.  Lastly, this study assumes that the predictive models found by Neumann are accurate and uneffected over the years by the changing generated future data. 

Data availibility limitated this research by forcing multiple imputation techniques to be applied to the gaps observed for certain variables. After combining multiple opensources, over half of the variables required imputation of their missing values. With a largely imputated data set then being used to generate future data, the level of uncertainty behind the numbers worsened the adequacy of the regression models. Additionally, computing power and time limited the variables extrapolated to only those found significant in a region's conflict prediction models as opposed to all the variables availible. A greater degree of fidelity could have been achieved by developing the future alternatives with more information provided by all of the variables recorded. Despite the inherent limitations of this research, it proceeds to provide national leadership with complete data, a tested forecasting method, and future, realistic country conflicts to consider when developing foreign policy and security stategies.

## Overview

This thesis is organized into 5 chapters including this introduction chapter, Chapter 1. Chapter 2 contains a literature review of prominent studies and methods relating to this research. Chapter 3 discusses the methodology of the study to impute the data and develop the alternative futures of conflict transitions. Chapter 4 details the results and analyses, and chapter 5 offers final conclusions, and possibilities for future research.

# Literature Review

## Overview

The purpose of this chapter is to provide a background of the previous influential research done on country conflict prediction that this research is built upon as well as an explanation of the existing contributions made to predict based future data. This chapter is broken down into three main sections: existing nation-state conflict modeling, applied imputation techniques, and related forecasting applications. The first section of this chapter focuses on the development of predictive models for nation-state conflict that lead to the very model employed by this research. The second section identifies similar imputation methods and comparison stategies that informed this research's handling of missing data. The final section provides a summary of related applications of explanatory forecasting efforts that this research's own generative alternative future method. This chapter ultimately aims to cover literature about the main models, methods, and applications related to this research.

## Previous Nation-State Conflict Models

Predicting world conflict has been a problem addressed by multiple studies. There have been different prediction methologies where researchers have defined conflict, the influential variables, and how best to group countries prior to predicting their conflicts. There have been varying accuracies achieved by these predictive modeling efforts. This section outlines the progress already made in predicting countries conflict status which is the basis of this research's generation of alternative world conflict futures.

The 2013 research, _Learning from the Past and Stepping into the Future: Toward a New Generation of Conflict Prediction_, focused on the benefits that prediction models of political conflict in a complicated geopolitical landscape could provide (CITE). The authors defended the importance of country conflict prediction and identified limitations in previous research. Previous research had fixated on including statistically significant variables while overlooking a variable's impact on a the model's overall predictive accuracy. Ward's developed a model of behavioral and instituational variables to predict the cumulative probability of civil war six months prior prior to it's onset in various countries. This hierarchial logit model's slope and intercept differed depending on different groups of nations and achieved a accurately predicted civil wars 95\% of the time. Ward's research was the first to put a greater deal of importance on prediction accuracy in addition to just building models with siginificant variables. Until the Ward study and Goldstone's efforts, conflict prediction models' precdition accuracies were capped at limited around 50\%. 

The study, _A Global Forecasting Model of Political Instability_, conducted by Dr. Jack Goldstone for the U.S. Central Intelligence Agency's Directorate of Intelligence predicted the onset of political instability two years prior to the conflict's start (CITE Goldstone). Goldstone's research took open source global data from 1955 to 2003 and performed a variety of predictive techniques to achieve 80\% accuracy distinguishing between countries that experienced instability from those that remained a constant level of political  (CITE Goldstone). Goldstone's study found a nonlinear five-category measure of regime type to be the most powerful predictor rather than economic conditions, demography, or geography (CITE Goldstone). Country conflict, the dependent variable, was defined as a revolutionary war, ethnic war, adverse regime changes, or genocides and politicides (CITE Goldstone). Of the predictive event history models, logistic regression, neural networks, and Markov processess tested, the simple logisitc regression model performed best with only four independent variables. These results gave insight for future researchers to the importance of fewer, major variables in reducing the unexplained variance of the conflict models as well as logistic regression being a favorable method political instability prediction. Goldstone's model was built on a world scale and ignored the differences between nations' locations. In fact, the sole region modeled seperately, Africa, included different variables for predicting country conflict which indicates towards the pertinence of regional differences. 

The Center for Army Analysis's research _Recognizing Patterns of Nation-State Instability that Lead to Conflict_ analyzed the influential factors in predicting country conflict relevant to Army operations. Shearer's work intiially mapped the top four intensity levels of an older, slightly different version of the HIIK conflict intensity into to two categories: peace and conflict (CITE). This indicator of a nation's conflict status was the model's dependent variable, and thirteen variables from unclassified data on the diplomatic, social, economic, and military factors of each country acted as the regressors (CITE). Pricipal component analysis was applied to better visualize the data in a reduced three dimensional feature space. The study further used a smoothing algorithm to forecast future vectors, and with k-Nearest Neighbors and Nearest Centroid algorithm, Shearer obtained a classification accuracy of 85\% for the stability of a nation over time (CITE). The reaserch introduced an understandable way to view the data and define a nation's likelihood of conflict while predicting conflict further into the future with comparable precision. The models were built on a global scale and resulted in unknown classifications for certain predictive techniques (CITE).

_Predicting Armed Conflict, 2010-2050_ predicted global and regional incidencies of armed conflict using a multinominal logit model trained on cross-sectional data on 169 countries from 1970-2009 (CITE). The model predictions were on the likelihood of a nation's transition between no conflict, minor conflict, and major conflict. The three transition states were determined by the combat related deaths per year. The preictions were calculated by simulating the behavior of the conflict variable implied by the estimates from their model. The regional based model building strategy, taken by the research accounted for countries' geographically driven differences. The world was divided into eight regions from a compressed version of the United Nations regional grouping and included unique regressors for each region. Six seperate models were developed using varying combinations of independent variables that emphasized the influence of conflict history, country development, and neighboring behavior on conflict status. The simulated future data was based on proposed scenarios and projections of demographic trends over time with the the multinomial logit coefficients changing yearly until simulating to convergence. This study set a precedent of a multi level conflict matrix that allowed for the inclusion of predicting ongoing conflicts. The study simultanously predicts escalation, onset, and termination of conflicts which expands the application of the work to global and regional prediction. 


## Applied Imputation Techniques



## Related Forecasting Applications


The simulated future data was accomplished through the use of projections of predictor variables, as provided by the UN World Population Prospects and the International Institute of Applied Systems Analysis. Using this data, Hegre predicts an overall decline in the global incidence level of violent conflict; a decline attributed to improvements in variables associated with infant mortality, education and youth bulges (Hegre et al., 2011). However, since these long term predictions are based on projections as opposed to actual data, the Hegre Model estimates should be interpreted as long-term global, and to a lesser extent regional, conflict trends, given projected conditions as opposed to specific national level predictions.


# Methodology

## Overview

This research explores imputation techniques to first fill missing gaps int the data and develop linear regression models to develop future alternatives of nation-state conflict for two major world regions. Section 3.2 describes the methodology used to develop the data set and imputation methods used to complete the data's missing observations. Section 3.3 outlines the development and building procedures for the linear regression models for each variable of interest. Section 3.4 

```{r, engine="tikz", eval = TRUE, fig.cap = "Methodology Overview", echo=FALSE}
\usetikzlibrary{shapes,arrows}
\pagestyle{empty}

\tikzstyle{block} = [rectangle, draw, fill=grey!20, 
text width=11em, text centered, rounded corners, minimum height=4em]

\begin{tikzpicture}[scale = .85, transform shape, node distance = 2cm, auto, >= triangle 60]
    % nodes
    \node [block] (init) {Collect data set};
    \node [block, right of = init, node distance = 5cm] (sec) {Imputation selection and implementation};
    \node [block, right of = sec, node distance = 5cm] (third) {Individual\\variable regression model generations};
    \node [block, below of = init, node distance = 3.5cm] (four) {Single step\\iterative future method};
    \node [block, right of = four, node distance = 5cm] (fifth) {Utilize country conflict logistic\\regression models};
    \node [block, right of = fifth, node distance = 5cm] (six) {Replicate for a given future data set};
    \node [block, below of = four, node distance = 3.5cm] (sev) {Multiple future data sets};
    \node [block, right of = sev, node distance = 5cm] (eight) {Statistical analysis of each future data set};
    \node [block, right of = eight, node distance = 5cm] (nine) {Conduct what if future analysis};

    \draw[-triangle 60] (init) -- (sec);
    \draw [->] (sec) -- (third);
    \draw [->] (third) |- ([xshift = 0cm, yshift = -1.75cm].northwest) -- (four);
    \draw [->] (four) -- (fifth);
    \draw [->] (fifth) -- (six);
    \draw [->] (six) |- ([xshift = 0cm, yshift = -5.65cm].northwest) -- (sev);
    \draw [->] 
      (sev) edge (eight)
      (eight) edge (nine);
    \draw [->, dashed] (six) |- ([xshift = 0cm, yshift = -5.075cm].northwest) -- (four);
\end{tikzpicture}

```

## Imputation 

### Original Data Set

The data utilized by this study is the same as the Neumann (CITE Neumann) study and build upond the Leiby (CITE) and Shallcross (CITE) studies. The data initially consisted of 182 countries from the Neumann, Leiby, and Shallcross studies from the 2004-2014 and the same independent variables analyzed by the Neumann's research. This study still imputed and used the Military Expenditure as a percent of government spending despite Neumann (CITE) removing from her work because of a high percentage of the variable being unobserved. This research added the same two additional technology variables, two derived border conflcit variables inspired by the Leiby (CITE) research, and dependent conflict transition variable as the Neumann (CITE) study. These generated variables are explained in further detail after the missing data observations were first imputed.

### Missing Data

This study assumed that all of the unobserved data is missing at random. This means that probability of being missing is not the same for all cases but within that group of data's observed values (CITE Buuren). The probability that a data point is missing only depends on observed data values and not any unobserved or outside it's group. Assuming the data is missing at random is the foundation for this research's applied imputation methods. The original data was missing observations for 21 of the 32 variables over the past ten years. The missing observations accounted for about 6.79\% of the data's total observations. After splitting the data by region, the missingness per region ranged between 3.22\% and 9.05\% of the entire regions observations. 

Before applying more complex imputation methods, the variable Polity IV's missing observations were filled using information provided by the fully observed Regime Type variable. Goldstone's CIA study created the Regime Type variable as an indicator of political instability (CITE Neumann #7). Regime type originally had 57 descriptors of a country's government, and Boekstein simplified the variable down to just a three level indicator (CITE Neumann #15). Regime type is observable and constant each year for every country analyzed in this study. The Polity IV is an integer variable ranging from -10 to 10 where a -10 means a country's government is fully autocratic and 10 fully democratic. Specific Polity IV indicators were given to those country's with anarchies, transitioning governments, or governments experiencing a foreign interruption. The missing observations for Polity IV were filled based on the Regime Type of a country using the mapping of the three levels of Regime Type as seen in Table XX.

```{r, xtable1, results='asis', eval=TRUE}
library(kableExtra)

Polity.transform <- data.frame(
  "Regime Type" = c("Central Ruling Party",
                  "Emerging, Transitional, Recent Change, and Disputed",
                  "Democratic"),
  'Corresponding Polity Value'   = c('-10','0','10')
)

#kableExtra::kable(text_tbl, "latex", booktabs = T) %>%
#  kable_styling(position = "center")
methods_table <- xtable::xtable(Polity.transform, caption = 'Mapping of Regime Type to Fill Missing Polity Values', label = 'table:polity.tranform', align = "llc")
print(methods_table, comment = F, include.rownames=FALSE, scalebox = 0.9, sanitize.text.function = function(x){x}, table.placement = "H")

```

Neumann's (CITE) research identified new groups of countries based on applying Modified K-Means Algorithm to the 2014 data for the selected 182 countries. The groupings found came from the algorithm's similiarities between data and location. Neumann's new groupings are how this study breaks down the 182 countries of interest, and her new COCOM 1 and 6 are the primary regions analyzed by this study. New COCOM 1 and 6 contain countries with historically violile conflict statuses which makes them of greater interest for analyzing future conflict transitions. 

### Mulitple Imputation by Chained Equations

Multiple imputation by chained equations (MICE) was the method used to impute the remaining missing observations. The MICE package in R allowed this method to be applied to each multivariate data set of Neumann's six world regions (CITE Mice R Package). Multiple imputation creates _m_ > 1 complete versions of the data by filling the missing observations with plausible data values (CITE Buuren). Using multiple imputed data sets helps address the statistical uncertainity involved with impututing data. The MICE algorithm is a fully conditional specification imputation method which means it imputes multivariate missing data in a variable-by-variable manner (CITE Buuren). MICE predicts a column of missing data as a the target variable in a regression equation with the all the other variables as the predictors unless other specified (CITE R MICE package). If a predictor is missing an observation, then the most recent iteration's imputation value is used to impute the target variable (CITE MICE package). MICE is a Markov chain Monte Carlo method in which the state space consists of of all imputed values. The MICE algorithm must satisfy three properties to converge, just as any Markov chain would converge to a stationary distribution.

  * irreducible, the chain must be able to reach all interesting parts of the state space
  * aperiodic, the chain should not oscillate between different staes
  * recurrence, all inresting parts can be reached infinitely often at least from almost all starting points
  
The first step in filling in the initial missing data observations was checking to see if the MICE algorithm was converging for each region. Van Burren identified there being no clear-cut method for determining whether the MICE algorithm has converged but that suitable imputations can be spotted from plotting one or more parameters versus the iteration number. The means and standard deviations were plotted for each variable's imputation streams. Healthy converges were categorized by freely intermingled different streams, without showing any trends and the variance between different sequences not being larger than the variance within each individual sequence. Below are an example of a healthy convergence when imputing freshwater per capita in South East Asia. 

```{r healthy convergence, eval = TRUE, fig.cap = 'Healhty-Convergence of the MICE Algorithm for Freshwater per Capita in South East Asia',echo=FALSE}
load("C:/Users/ZKane/OneDrive/Documents/KaneThesis/healthy_convergence.RData")

```

After looking at MICE applied to this analysis's data and seeing previous research's MICE convergences, around 20 iterations there was sufficient convergence by the algorithm. Moving forward each imputation conducted was run for 20 iterations. MICE allows for several different imputation techniques to be specifically applied to each variable every pass. _m_ of these chains are calculated in parallel, and after around 15-20 iterations for one regression chain, the regression coefficents for each missing variables' models are likely to converge (CITE burren page 116). MICE utilizes the columns of fully observed data in these chains. Imputing with a subset of only the missing data or simplified data set may deprive the MICE algorithm of information from the observed data. For this reason, each imputation was performed with the missing and complete columns of data. Multiple imputation procedurely will impute the data, analyze each imputed data set seperately, and pool the results. The intital imputation began with investigating which MICE method resulted in the data most similiar to the distribution of observed data. The five mice packages tested are shown in Table XX. 

```{r, xtable2, results='asis', eval=TRUE}
library(kableExtra)

imp_methods <- data.frame(
  Method = c("cart", "pmm", "norm", "rf", "mean"),
  Description = c(
    "Classification and regression trees",
    "Predictive mean matching",
    "Bayesian linear regression",
    "Random forrest",
    "Unconditional mean imputation"
  )
)

#kableExtra::kable(text_tbl, "latex", booktabs = T) %>%
#  kable_styling(position = "center")
methods_table <- xtable::xtable(imp_methods, caption = 'Imputation Methods Tested', label = 'table:imp_methods_tested')
print(methods_table, comment = F, include.rownames=FALSE, scalebox = 0.9, sanitize.text.function = function(x){x}, table.placement = "H")
```

Between all of the six regions, there were average about 12 variables per region that required imputation by MICE. MICE has the ability to impute and utilize categorical varibales. MICE creates dummy variables for the categorical variables and generates their regressions and resulting imputations from these (CITE MICE R package). None of the variables requiring imputation were categorical, but there were categorical various such as Regime Type that were included in the prediction of other missing variables. The MICE imputation methods investigated were selected based on there not any missing categorical variables and trying to test a wide variety of methods. Imputation using classification and regression trees (CART) seek predictors and cut points in the predictors used to divide up the sample of data. The data is split up repeatidly until a binary tree is build to determine the target variable (CITE Van Buuren). CART methods for imputation are robust against outliers, can handle multicollinearity and skewed distributions, and are able to fit interations and nonlinear relationships (CITE Van Buuren). Predictive mean matching (pmm) is an imputation technique which utilizes the observed data to calculate the predicted target value. It takes a random draw from the candidate donors from the complete cases with predicted values closest to the predicted missing entry value (CITE Van Buuren). The norm method applies Bayesian linear regression that uses parameter uncertainty from random draws from a posterior probability distribution based on the observed data (CITE Van Buuren). 

### Testing Imputation Methods

Each of the five MICE methods were run to develop five different imputed data sets per region and then compared using the Kolmogorov-Smirnov (K-S) and non-parametric, 2-sample Anderson-Darling (A-D) tests. The K-S test looks at if the imputed data values are similiar to the observed data values. This test makes the assumption that the imputed data should follow the same distribution as the observed data (CITE Abayomi, Brantley #36). Engmann and Cousineau (CITE Brantley 37) compared both the A-D and K-S tests and found that the A-D performed better when analzying moments and small differences in the tails of distributions. Based on these findings, the A-D test for this analysis will be the main differentitor between imputation methods (CITE Brantely). The null hypothesis behind both of these tests is that the distributions come from the same parent distribution. A small p value indicates that the imputed data and original data are significantly different and can be interepreted as a poor imputation method. For some variables missing a high percentage of observations such as Freshwater per Capita which was missing for ~74\% of observations, no imputation method was able to find a statistical similarity between that method's imputed data and the observed data.

In some literature the mean absolute error and root mean square error have been used to assess the performance of an imputation method. This analysis didn't utilize these measures of accuracy based on the difference between true and the imputed data. Due to there being so few complete cases for certain variables, evaluation metrics that were based on knowing the true values for missing data weren't implemented. Van Buuren also detailed the shortcomings of treating imputation as a prediction problem geared towards finding the best value. The goal of multiple imputations is "to obtain statistically valid infrences from incomplete data" (CITE Van Buuren). Also treating imputations as methods to enhance the classification accuracy may favor strange imputation methods (CITE Van Buuren). For these reasons, evaluating and choosing an imputation method becomes an increasingly complex problem. Van Buuren's warning as well as the conflicting results and ties between the K-S and A-D statisitical tests begged for another imputation evaluation metric to decide the optimal method. Diagnostic graphs were implemented lastly to asses the plausibility of each imputation method: box and whisker plot and kernel density plots. The box and whisker plot was chosen over strip plots based on Van Buuren's recommendation that the box and whisker plot is more appropriate for large data sets. Both these plots compare the discrepancyies between the observed and imputed data. Dramatic differences would signify a possibility that something with the imputed data needed further investigating (CITE Van Buuren). The diagnostic plots were used to validate the results of the A-D and K-S tests as well as break any potential ties from seeing which imputed values from a given are more reasonable. For example the variable freshwater per capita from the Arab region had all five inputed values insignificantly different from the observed data when tested using the A-D and K-S tests. The box and whisker plots and density plots were then examined to learn more differences between imputation techniques. A suitable imputation technique would produce values that could be observed if the data had not been missing at all (Cite MICE Article page 42). The best performing plots had imputed data visually closest to the observed data. The diagnostic plots After applying applying the K-S and A-D statistical tests and inspecting the diagnostic plots, the imputation methods were decided for each variable in a given region. 

```{r, xtable3, results='asis', eval=TRUE, cache=TRUE}
load("C:/Users/ZKane/OneDrive/Documents/KaneThesis/completed_SE_asia.RData")
load("C:/Users/ZKane/OneDrive/Documents/KaneThesis/completed_arab_imp.RData")
load("C:/Users/ZKane/OneDrive/Documents/KaneThesis/SE_Asia_Mobile_imp.RData")

methods_SE_asia <- data.frame(jm_SE_asia$method[which(jm_SE_asia$method != "")])
methods_arab <- data.frame(jm_arab$method[which(jm_arab$method != "")])
methods_SE_asia_mobile <- data.frame(jm_SE_asia_Mobile_Cells$method["Mobile.Cell.Subs"])
names(methods_SE_asia_mobile) <- names(methods_SE_asia)
methods_SE_asia <- rbind(methods_SE_asia,methods_SE_asia_mobile)

library(data.table)
methods_arab <- setDT(methods_arab, keep.rownames = TRUE)[]
methods_SE_asia <- setDT(methods_SE_asia, keep.rownames = TRUE)[]
methods_SE_asia_mobile <- setDT(methods_SE_asia_mobile, keep.rownames = TRUE)[]
methods <- merge(methods_arab, methods_SE_asia, by = "rn", all = TRUE)
colnames(methods) <- c("Variable", "Arab", "South East Asia")
library(xtable)

xtd2 <- xtable::xtable(methods, caption = 'Imputation Methods Used for Each Variable by Region',
                       align = "llcc", label = 'table:imp_methods')
print(xtd2, comment = F, include.rownames=FALSE, scalebox = 0.8,
      sanitize.text.function = function(x){x}, table.placement = "H")
```

### Imputation Challenges

A problem that aross specifically with the South East Asia region is some variables are linearly related. When the MICE algorithm builds the regression equation to predict a missing value, a variable that is a linear combination of another will result in a singularity error that breaks the MICE algorithm. To fix this, the redundent variables must be excluded from the set of predictor variables used by MICE. The dependent variables can be identified by the last eigenvector of the covariance matrix of the data after performing listwise deletion. The variable Mobile Cell Subscriptions was highly correlated ($>0.5$) with multiple variables. Mobile Cell Subscriptions by far had the smallest loading ($2.012761e-11$) on the on the last eigenvector of the covariance matrix. For these reasons Mobile Cell Subscriptions was imputed individually using the MICE algorithm. When removed the singularity errors ceased to disrupt the MICE algorithm.  

## Regression Models

With the complete data from the previous ten years since 2014, linear regression models were built for each variable of interest. Neumann's model's for regions in and out of conflict defined the variable that would be of interest for this research. The variables required in Neumann's models will be required to predict future conflict transitions. The regression equations define each variable to be explained by the rest of the data. Each regression model was built with the goal of achieving the most parsimonium model from the other variables in the data. Before the regression models were build and reduced, the data set required certain variables gereated by Neumann's research be developed using the complete data. Van Buuren stressed the importance of developing imputations before any additional variables are generated (CITE Van Buuren). Additionally certain variables that are derived from the rest of the data didn't require regressions to be build since their values in future scearios can be calculated then. 

### Variable Development

After filling all the missing gaps in the data, variables of interested were developed to match the data set of previous works such as Neumann and Shallcross. A Government variable was created based on the values of the Polity variarble to indicate a nation's government type. The six categories of this variable are shown in Table \@ref(tab:govmapping).

```{r govmapping, xtable, results='asis', eval=TRUE}

Government_mapping <- data.frame(
  '1' = c("-10 to -6", "-5 to 5", "6 to 10", "-66", "-77", "-88"),
  '2' = c('0','1','2','3','4','5'),
  '3' = c("Autocratic",
                         "Emerging Democracy",
                         "Democratic",
                         "Foreign Interruption",
                         "Anarchy",
                         "Transitional")
)

#KableExtra::kable(Government_mapping, "latex", booktabs = T) %>%
#  kable_styling(position = "center")
government_table <- xtable::xtable(Government_mapping, caption = 'Goverment Type Mapping from Polity', label = 'tab:gov_mapping', align = "cccc")
names(government_table) <- c("Original Polity Value", "Government Type Number",
                             "Government Type")
print(government_table, comment = F, include.rownames=FALSE, scalebox = 0.9,
      sanitize.text.function = function(x){x}, table.placement = "H"
      )

```

The Percent Border Conflict is consistent with the percent border conflict variable in Neumann (CITE Neumann) and border conflict variable in Shallcross (CITE Shallcross) and Boekestein (CITE BOEK). The Percent Border Conflict is calculated by summing the product of all the percentages neighboring country border a country of interest and the neighboring countries HIIK level of conflict intensity for a given year. Islands were assumed to have no neighboring countries and a zero Percent Border Conflict. Equation XX defines the Percent Border Conflict Variable 
\begin{gather}
PctBC_{ij} = \sum_{k=1}^{n} H_{kj}p_{k} \text{where} \nonumber\\
n = \text{number of bordering countries for country $i$} \nonumber\\
H_{kj} = \text{HIIK conflict intensity level for country $k$ in year $j$} \nonumber\\
p_{k} = \text{percent of border country $i$ shares with county $k$} \\
i = \text{Country} \in \{1,2, ..., 182\} \nonumber\\
j = \text{Year} \in \{2004, ..., 2015\} \nonumber\\
k = \text{Bordering country} \nonumber
\end{gather}

The Average Border Conflict measures the average conflict intensity around a given country in a given year and is consistent with Neumann's (CITE Neumann) average border conflict variable. Islands are treated as having no bordering countries. The calculation for the Average Border Conflict is defined by Equation XX. 
\begin{gather}
AvgBC_{ij} = \frac{\sum_{k=1}^{n} H_{kj}}{n} \text{where} \nonumber\\
n = \text{number of bordering countries for country $i$} \nonumber\\
H_{kj} = \text{HIIK conflict intensity level for country $k$ in year $j$} \\
i = \text{Country} \in \{1,2, ..., 182\} \nonumber\\
j = \text{Year} \in \{2004, ..., 2015\} \nonumber\\
k = \text{Bordering country} \nonumber
\end{gather}

The Binary Border Conflict variable is consistent with the binary border conflict variable in both the Neumann (CITE Neumann) and Leiby (CITE Leiby) studies. It is a binary representation for a given country if one of their neighboring nations meets a certain conflict intensity in a given year. Islands are again assumed to have a zero score as they are not neighbored by any nations. Binary Border Conflict score is defined for a given country by Equation XX.
\begin{gather}
BinBC_{ij} = 
  \begin{cases}
    1 & \quad \text{if $H_{kj} \ge 3$ for any country bordering country $i$} \\
    0 & \quad \text{otherwise}
  \end{cases}
\nonumber\\
H_{kj} = \text{HIIK conflict intensity level for country $k$ in year $j$} \\
i = \text{Country} \in \{1,2, ..., 182\} \nonumber\\
j = \text{Year} \in \{2004, ..., 2015\} \nonumber\\
k = \text{Bordering country} \nonumber
\end{gather}

The dependent variable, Conflict Transition, is a binary representation if a country has changed conflict status since the previous year. Conflcit status is defined by the mapping a country's HIIK conflict intensity level in a given year. HIIK scores of 0, 1, and 2 are mapped to a 0 for the conflict status and indicate a country is not in conflict that year. HIIK scores of 3, 4, and 5 are mapped to a conflict status of 1 and represent a country is in state of conflict in that given year. The Conflict Transition binary variable for a country in a given year depends on the current and previous years conflict status. Conflict Transition is equal to 1 if the conflict status of a given year _i_ is not equal to the conflict status of the previous year _i-1_. Table XX below represents this mapping from conflict status for years _i-1_ and _i_ to the binary Conflict Transition variable in year _i_. 

```{r conflicttransitionmapping, xtable, results='asis', eval=TRUE}

conflict_transition <- data.frame(
  '1' = c("0 = Not In Conflict", "1 = In Conflict","0 = Not In Conflict", "1 = In Conflict"),
  '2' = c("0 = Not In Conflict", "1 = In Conflict","1 = In Conflict","0 = Not In Conflict"),
  '3' = c("0 = Not In Conflict", "0 = Not In Conflict","1 = In Conflict","1 = In Conflict")
)

#KableExtra::kable(Government_mapping, "latex", booktabs = T) %>%
#  kable_styling(position = "center")
conflict_transition_map <- xtable::xtable(conflict_transition, caption = 'Mapping of Conflict Transition', label = 'tab:conflict_transition_mapping', align = "ll|l|l")
names(conflict_transition_map) <- c("Conflict Status Yr $i-1$", "Conflict Status Yr $i$",
                             "Conflict Transition Yr $i$")
bold <- function(x) {paste('{\\textbf{',x,'}}', sep ='')}
print(conflict_transition_map, comment = F, include.rownames=FALSE, scalebox = 0.9,
      sanitize.text.function = function(x){x}, table.placement = "H", hline.after = c(-1,0,2,nrow(conflict_transition_map)),
      sanitize.colnames.function = bold, booktabs = T
      )

```

### Model Building Procedure

Linear regression models were build for variables that were significant in Neumann's logisitic regression models that predict a country's Conflict Transition. Linear regression models were build to statistically define each individual variable of interest by the other variables in a given region. Testing was completed to include higher order terms and interaction terms in these models, but due to the higher achieved adjusted $R^2$ values, models were only build using the main effects. The complete data set used to build the models consists of all five of the imputed data sets stacked on top of each other. This goes against Van Buuren's advice to pool the resulting models, but due to the desire for point estimates defining each variable of interest, the simplier method of stacking the imputations was preferred. With less than $10\%$ of the observations missing from the two new world regions of interest, the research is impacted less from weight of the missing data. The stacked imputed data results in _m_ x _n_ complete records where _m_ still being the number of imputed data sets. The statistical analysis thus becomes a weighted linear regression with a weighted factor of $1/m$ applied to each record. Having low levels of missingness and the point estimates generated from the stacked complete data being unbiased (CITE page 158) makes treating the imputed data as a stacked, long data set sufficient for the purposes of this research.

Stepwise regression is the primary method used to generate parsimonous linear regression models for each variable. This method iteratively removes predictor variables while computing a linear regression model each time. Each time a regression is rerun, each predictor variable's associated p value is assessed to see if it is within a specified acceptable range. By deleting variables from the model, the precision of point estimates of the remaining in the model are improved (CITE intro to linear). The stepwise method was run using JMP with chosen p value for entering and removing a variable of 0.05. Stepwise regression operates in a direction to either enter or remove a term with the smallest or largest p value. The mixed option in JMP alternates between a forward and backward selection to include the only significant terms. Models were building stepping from a null and full model using the mixed selection method. Most times the reduced models were the same, but if there were any differences, the model that achieved the higher $R^2_{adj}$ was chosen. The coefficient of multiple determination, $R^2$, is a measure of model adequacy that represents the proportion of variance explained by the regression. Adding regressors to the model will improve $R^2$ but can still produce a worse model and larger error mean square by losing one degree of freedom for error (CITE intro). A low value of $R^2$ for this research indicates a poorly specified model (CITE intro). $R^2$ will never decrease from adding a variable to the model, so it is important in varaibel selection to include another evaluation statistic. $R^2_{adj}$ will only improve if the variable added reduces the residual mean square to prevent overfitting (CITE intro). This research will reference to $R^2_{adj}$ when evaulating models in stepwise regression. Interaction terms were also selectively included in models with lacking $R^2_{adj}$ (<0.5). In an effort to devleop parsimonious models, only second order interaction terms were considered. With the interactions factored into the model, the Arab region produced 74 possible variables while there were 209 possible variables in the SE Asia region. Stepwise regression reduced these numbers for the models requiring higher $R^2_{adj}$. All of the Arab region models were built with interactions, but only Population Growth's interactions were necessary in South East Asia.
  
### Assessing Model Adequacy

The final stepwise models were analyzed to ensure they met all the assumptions of linear regression. Linear Regression assumes the error terms or residuals must be independent, normal, and random variables with mean of $0$ and constant variance $\sigma^2$ (CITE data mining and analysis). Graphically, these linear regression assumptions can be evaluated using a normal probability plot of the residuals and a plot of the standardized residuals against the predicted values. A normal probability plot of the residuals is a quantile-quantile plot where quantiles of a particular distribution are plotted against the quantiles of the standard normal distribution to identify deviations from normality (CITE data mining). If a distribution is normal then a majority of the points in the graph should fall close to the diagonal reference line. Statistically, there are lot of different ways to test normality with each depending on the data at hand. The deviations from normality were calculated using the Cramer-Von Mises test where the null hypothesis is that the distribution of the errors follows a normal distrubition. It is a simplified version of the Anderson-Darling test that does not provide as much weight to the tails of the distribution. It is not the most powerful empirical distribution test, but this research choose to have more relaxed normality standards to avoid conducted more in depth outlier analysis and accept simplier models sooner. The Cramer-Von Mises statistic is calculated as,
\begin{gather}
CVM = \frac{1}{12n} + \sum_{i=1}^{n} [F_0(x_{(i)})-\frac{2i-1}{2n}]^2
\end{gather}
where $n$ is the sample size and $x_i$'s are the ordered data (CITE CVM). P value scores lower than $0.05$ indicate a regression model's errors don't follow a normally distrbuted. The package oslrr (CITE olsrr) in R was used to test the normality of each variable of interests' residuals.

A plot of the standardized residuals against the predicted values helps identify patterns in the variance of a model's residuals. Linear regression assumes homoscedasticity, constant variance, and independence of a model's error term. These plots tests both of these assumptions and should not represent any clear funnel, linear, or u-shaped pattern. If the variance of the errors is increasing or decreasing over time, confidence intervals for new predictions will tend to be unrealistic (CITE DUKE). The plots should be evenly spread out and distanced from the x-axis (CITE data mining). Statistically, these assumptions are tested using the Breusch Pagan test for homogenity of variances from the olsrr package (CITE olsrr) in R where the null hypothesis is that the variance is constant based on a chi-squared test. This test sees whether the variance of the errors from a regression is dependent on the values of the independent variables (CITE cran heter). Below in Table XX the final models' adequacy tests can be found and any respective transformations.

```{r modeladeqarab, xtable, results='asis', eval=TRUE}

load("C:/Users/ZKane/OneDrive/Documents/KaneThesis/Arab_reg_table.Rda")
load("C:/Users/ZKane/OneDrive/Documents/KaneThesis/SE_Asia_reg_table.Rda")
reg_table <- rbind (Arab_reg_table, SE_Asia_reg_table)
reg_table[c(2,4,6,8:10,12,13),5] <- "<0.0001"
reg_map <- xtable::xtable(reg_table, caption = 'Regression Model Adequacy Check', label = 'tab:reg_models', align = "lcccccc", digits=c(0,4,4,4,4,4,4))

names(reg_map) <- c("$R^2$", "$R^2_{adj}$", "F-Test",
                             "Cramer-Von Mises", "Normality", "Transformation")
rownames(reg_map) <- c("Arab Mobile Cell Subscriptions","Arab Population Density","Arab Percent Border Conflict","Arab Fertility Rate","Arab Trade Percent GDP","SE Asia Internet Users","SE Asia Life Expectancy","SE Asia Mobile Cell Subs","SE Infant Mortality Rate","SE Asia Population Growth","SE Asia Arable Lands","SE Asia Avg Border Conflict", "SE Asia Freshwater per Capita")
#bold <- function(x) {paste('{\\textbf{',x,'}}', sep ='')}
print(reg_map, comment = F, scalebox = 0.75,
      sanitize.text.function = function(x){x}, table.placement = "H",
      booktabs = T, include.rownames = TRUE
      )

```

### Transformations

Certain variables regression models were improved after the dependent variarbles were transformed. These transformations were performed to possible improved the model's $R^2_{adj}$, normality, or homoscedasticity statistics. If a transformation tested raised any of these categories, then the transformation was made for model from here on out. The square root was taken for the Population Density variable in the Arab region ($\sqrt{Population Density}$). The transformation improved a higher $R^2_{adj}$ but didn't improve the model's homoscedasticity or nomarlity violations. The log was taken of a few variables which helped some of those models to fulfill the linear regression assumptions ($log(y_i)=\beta_0+\beta_{1}x_{1i}+...+\beta_kx_{ki}+e_i$). Mobile Cell Subscriptions in the South East Asia region was transformed initally just by the square root, but the model continued to improve further by then taking the fourth root ($\sqrt[4]{Mobile Cell Subscriptions}$). JMP offered other transformations that were tested but didn't out perform the three ones (log, square root, and fourth root) that were actually done. 

Even after the transformations were added, the regression models didn't statistically meet all of the assumptions of linear regression. This research recognizes the discrepencies in the models, but accepts the models, and will proceed with them for developing future alternatives of world conflict. 

## Iterative Forecasting 

With the data properly imputed and regression models built for each variable of interest, the alternative futures were developed. An iterative explanatory approach inspired by univariate imputation techniques was the primary approach to generating the complete future data sets. For each region individually, Neumann's conflict prediction models were applied each year to see find a probability of a country transitioning in or out of a state of conflict. Each variable value would be calculated using the previous years values using the regression equations created based on the other variables of interest in their respective region. To improve on the predicted value of these equations, random noise was added to the predicted value. This noise introduces variability that reflects the inherent inaccuracy associated with predicting variables from an insufficient subset of variables. Van Buuren (CITE) injects noise from a random draw from the normal distribution based on the assumption that the observed data is normally distributed around the regression line. Due to the regression equations largely violating this assumption, the noise instead came from a random draw from the residuals of the variables' regression equations. Before Neumann's conflict transition logistic regressions could be applied, the complete predicted data for the next year were assessed for operational feasibility. This varied by region and variable, but the variables' values were restricted as to not exceed two times the region's largest value and one half of the region's smallest value recorded in the last ten years. These conservative limits placed on the prediction values plus the noise elliminated variables reaching inconceivable highs or lows and maintained the operational relevancy of this research. 

Certain variables identified as signficant to predicting conflict transitioning were calculated based on the new variables' values rather than by their own regression equations with noise or were assumed not to be changing over the years. The two year conflict intensity trend of a country was calculated manually based on the previous year's HIIK conflict intensity score minus the country's HIIK conflict intensity score from two years ago all divided by six for the six different HIIK levels. The regime and government type variables were assumed not to change year to year because they are binary indicators of levels ranging from autocracy to democracy for a nation which for this research's purposes wouldn't change over the years of focus. A country's government type is considered a hard to change factor, so the iterative forecast method treated a nation's government as constant through the course of any conflict transitions. The HIIK conflict intensity level each year was calculated based on the probability that a nation would transition in or out of conflict. The new year's data would be plugged into Neumann's logistic regression equations depending on the conflict status of the previous year. From there the predicted value of the logisitic regression would be converted into a probability. Recall that the formula for a logistic regression function is as follows.

\begin{equation}
ln(\frac{p}{1-p})=\beta_0+\beta_1x_1+...+\beta_nx_n
\end{equation}

The formula for logistic regression contains p, the probability and n, the number of variables. To solve for p, the exponential of the predicted value of logistic regression was divided by one plus the same exponential of the predicted value from the logistic regression. 
 
\begin{equation}
p=\frac{exp(\beta_0+\beta_1x_1+...+\beta_nx_n)}{1+exp(\beta_0+\beta_1x_1+...+\beta_nx_n)}
\end{equation}

A higher probability indicates that a nation has a higher chance of transitioning conflict statuses while a smaller probability means a country's conflict status will remain at the same level of conflict for that year. A 0.5 probability cutoff was used to decided which direction a country would transition: transition or stationary. A random draw was taken between 0 and 1 to compare to the calculated transition probability. The random draw comparison represents the uncertainty that given a country's probability to transition conflict status, a country may not actually transition in the direction the logistic regression equations found to have the highest probability. If the random draw, in the direction of transition or remaining the same exceeds the logistic regression equation's probability of conflict transition than the country's conflict will in fact not do what it has the highest probability of doing. For example, if a country was in conflict last year and the in conflict equation for that region found a transition probability of 0.91, the country is likely to transition to being out of conflict. A random draw would be taken between 0 and 1, and say the random draw was 0.95, than due to the random draw exceeding the transition probability in the likely transition direction, than the country would remain in conflict. 

HIIK conflict intensity was mapped each year based on the conflict transition probability and random draw comparison. If a country, after taking and comparing the random draw, transitions in the direction indicated by the transition probability than the HIIK conflict intensity was just mapped following the below mapping. 

```{r in_HIIKmapping, xtable, results='asis', eval=TRUE}

in_conflict_HIIK_transition <- data.frame(
  '1' = c("Transition and Does", "", "",
          "Transition and Doesn't",
          "Remain and Does", "", "",
          "Remain and Doesn't"),
  '2' = c("Not In Conflict", "", "",
          "In Conflict", 
          "In Conflict",  "", "",
          "Not In Conflict"),
  '3' = c("(1-$5/6$) = 0", "($5/6$-$4/6$) = 1", "($4/6$-$3/6$) = 2",
          "3", 
          "($3/6$-$2/6$) = 3", "($2/6$-$1/6$) = 4", "($1/6$-0) = 5",
          "2")
)


in_HIIK_map <- xtable::xtable(in_conflict_HIIK_transition, caption = 'Previous Year In Conflict Mapping HIIK Conflict Intensity ', label = 'tab:in_HIIK_mapping', align = "ll|c|c")
names(in_HIIK_map) <- c("Random Draw Comparison",
                                    "Conflict Status Year $i$", "Year $i$ HIIK Mapping")
bold <- function(x) {paste('{\\textbf{',x,'}}', sep ='')}
print(in_HIIK_map, comment = F, include.rownames=FALSE, scalebox = 0.75,
      sanitize.text.function = function(x){x}, table.placement = "H", hline.after = c(-1,0,3,4,7,nrow(in_HIIK_map)),
      sanitize.colnames.function = bold, booktabs = T
      )

```

For a country that was in conflict the previous year, the random draw comparison column reads transition when the transition probability calculated using Nuemann's in conflict logistic regression equations yield a probability over 0.5. If the random draw is larger than the transition probability, the column will read transition and doesn't. Since the country's conflict is behaving contradictory to how the equations predict, the HIIK conflict intensity is mapped to being the lowest in conflict score of 3. Otherwise, the column reads transition and does, meaning the country for that year transitions to not in conflict and it's HIIK conflict intensity is inversly mapped based on an even division between 0.5 and 1 for the out of conflict HIIK conflict intensity scores. The same approach is taken when a country in conflict is supposed to stay in conflict (transition probability < 0.5) except now the country will only do the opposite of the predicted transition probability if the random draw is less than the transition probability. In the case that the random draw is that small and the country doesn't stay in conflict, HIIK conflict intensity is set as the lowest not in conflict score of 2. When the previously in conflict country should remain in conflict and does, the transition probability is directly mapped to the top three HIIK in conflict scores based on an even division of 0.5 to 0 as seen above. The proceeding mapping of a country that was not in conflict the previous year is mapped in the same manor but with some of the mappings flipped accordingly. 

```{r out_HIIKmapping, xtable, results='asis', eval=TRUE}

out_conflict_HIIK_transition <- data.frame(
  '1' = c("Transition and Does", "", "",
          "Transition and Doesn't",
          "Remain and Does", "", "",
          "Remain and Doesn't"),
  '2' = c("In Conflict", "", "",
          "Not In Conflict", 
          "Not In Conflict",  "", "",
          "In Conflict"),
  '3' = c("(1-$5/6$) = 5", "($5/6$-$4/6$) = 4", "($4/6$-$3/6$) = 3",
          "2", 
          "($3/6$-$2/6$) = 2", "($2/6$-$1/6$) = 1", "($1/6$-0) = 0",
          "3")
)

out_HIIK_map <- xtable::xtable(out_conflict_HIIK_transition, caption = 'Previous Year Not In Conflict Mapping HIIK Conflict Intensity ', label = 'tab:out_HIIK_mapping', align = "ll|c|c")
names(out_HIIK_map) <- c("Random Draw Comparison",
                                    "Conflict Status Year $i$", "Year $i$ HIIK Mapping")
bold <- function(x) {paste('{\\textbf{',x,'}}', sep ='')}
print(out_HIIK_map, comment = F, include.rownames=FALSE, scalebox = 0.75,
      sanitize.text.function = function(x){x}, table.placement = "H", hline.after = c(-1,0,3,4,7,nrow(out_HIIK_map)),
      sanitize.colnames.function = bold, booktabs = T
      )

```

HIIK conflict intensity was an important variable to map as it was included in multipe variables' explanatory regression equations previously built. It depends on the conflict status of a country, so it was calculated iteratively each year after the transition probability equations were already applied.

# Analysis and Results

This is the fourth chapter of your thesis

# Conclusions

This is the final chapter of your thesis.












