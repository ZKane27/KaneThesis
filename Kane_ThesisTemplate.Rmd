---
title:        "`r DODschools::noTouch('metadata.yml')$document$title`"
designator:   "`r DODschools::noTouch('metadata.yml')$document$designator`"
doctype:      "`r DODschools::noTouch('metadata.yml')$document$type`"
pages:        "`r DODschools::noTouch('metadata.yml')$document$pages`"
abstract:     "`r DODschools::noTouch('metadata.yml')$abstract`"
dedication:   "`r DODschools::noTouch('metadata.yml')$dedication`"
acknowledge:  "`r DODschools::noTouch('metadata.yml')$acknowledgement`"
vita:         "`r DODschools::noTouch('metadata.yml')$vita`"
degree:       "`r DODschools::noTouch('metadata.yml')$degree`"
program:      "`r DODschools::noTouch('metadata.yml')$program`"
distro1:      "`r DODschools::noTouch('metadata.yml')$distro_thesis[1]`"
distro2:      "`r DODschools::noTouch('metadata.yml')$distro_thesis[2]`"
author:
  name:       "`r DODschools::noTouch('metadata.yml')$author$fullname`"
  dept:       "`r DODschools::noTouch('metadata.yml')$author$dept`"
  rank:       "`r DODschools::noTouch('metadata.yml')$author$rank`"
  service:    "`r DODschools::noTouch('metadata.yml')$author$service`"
  prevdegree: "`r DODschools::noTouch('metadata.yml')$author$currentDegree`"
  email:      "`r DODschools::noTouch('metadata.yml')$author$email`"
advisor:
  name:       "`r DODschools::noTouch('metadata.yml')$advisor$name`"
  department: "`r DODschools::noTouch('metadata.yml')$advisor$department`"
  rank:       "`r DODschools::noTouch('metadata.yml')$advisor$rank`"
  service:    "`r DODschools::noTouch('metadata.yml')$advisor$service`"
  degree:     "`r DODschools::noTouch('metadata.yml')$advisor$currentDegree`"
  phone:      "`r DODschools::noTouch('metadata.yml')$advisor$phone`"
  email:      "`r DODschools::noTouch('metadata.yml')$advisor$email`"
reader1:
  name:       "`r DODschools::noTouch('metadata.yml')$reader1$name`"
  department: "`r DODschools::noTouch('metadata.yml')$reader1$dept`"
  rank:       "`r DODschools::noTouch('metadata.yml')$reader1$rank`"
  service:    "`r DODschools::noTouch('metadata.yml')$reader1$service`"
  prevdegree: "`r DODschools::noTouch('metadata.yml')$reader1$currentDegree`"
#reader2:
#  name:       "`r DODschools::noTouch('metadata.yml')$reader2$name`"
#  department: "`r DODschools::noTouch('metadata.yml')$reader2$dept`"
#  rank:       "`r DODschools::noTouch('metadata.yml')$reader2$rank`"
#  service:    "`r DODschools::noTouch('metadata.yml')$reader2$service`"
#  prevdegree: "`r DODschools::noTouch('metadata.yml')$reader2$currentDegree`"
#reader3:
#  name:       "`r DODschools::noTouch('metadata.yml')$reader3$name`"
#  department: "`r DODschools::noTouch('metadata.yml')$reader3$dept`"
#  rank:       "`r DODschools::noTouch('metadata.yml')$reader3$rank`"
#  service:    "`r DODschools::noTouch('metadata.yml')$reader3$service`"
#  prevdegree: "`r DODschools::noTouch('metadata.yml')$reader3$currentDegree`"
sf298name:    "`r DODschools::noTouch('metadata.yml')$author$sf298name`"
contractnum:  "`r DODschools::noTouch('metadata.yml')$sf298$contractnum`"
grantnum:     "`r DODschools::noTouch('metadata.yml')$sf298$grantnum`"
prognum:      "`r DODschools::noTouch('metadata.yml')$sf298$programnum`"
projnum:      "`r DODschools::noTouch('metadata.yml')$sf298$projectnum`"
tasknum:      "`r DODschools::noTouch('metadata.yml')$sf298$tasknum`"
worknum:      "`r DODschools::noTouch('metadata.yml')$sf298$workunitnum`"
keywords:     "`r DODschools::noTouch('metadata.yml')$sf298$keywords`"
sponsor:
  title:    "`r DODschools::noTouch('metadata.yml')$sf298$sponsor$title`"
  subtitle: "`r DODschools::noTouch('metadata.yml')$sf298$sponsor$subtitle`"
  address1: "`r DODschools::noTouch('metadata.yml')$sf298$sponsor$address1`"
  address2: "`r DODschools::noTouch('metadata.yml')$sf298$sponsor$address2`"
  phone:    "`r DODschools::noTouch('metadata.yml')$sf298$sponsor$phone`"
  email1:   "`r DODschools::noTouch('metadata.yml')$sf298$sponsor$email1`"
  email2:   "`r DODschools::noTouch('metadata.yml')$sf298$sponsor$email2`"
  acronym:  "`r DODschools::noTouch('metadata.yml')$sf298$sponsor$acronym`"
  rptnum:   "`r DODschools::noTouch('metadata.yml')$sf298$sponsor$report_number`"
graddate:   "`r DODschools::noTouch('metadata.yml')$grad_date`"
date:       "`r format(Sys.Date(), '%B %Y')`"
sf298_date: "`r format(Sys.Date(), '%d-%m-%Y')`"
dissertation: "`r DODschools::noTouch('metadata.yml')$dissertation`"
cite_style: "`r DODschools::noTouch('metadata.yml')$cite_style`"
cite_shape: "`r DODschools::noTouch('metadata.yml')$cite_shape`"
output: 
  DODschools::afit_thesis:
    includes:
      in_header:    scripts/tex/in_header.tex
      before_body:  scripts/tex/before_body.tex
      after_body:   scripts/tex/after_body.tex
---

```{r echo=FALSE, message=FALSE, warning=FALSE}

pacman::p_load(devtools,
               knitcitations,
               RefManageR,
               xtable,
               sas7bdat,
               dplyr,
               survival,
               flexsurv,
               knitr,
               formattable,
               data.table,
               kableExtra,
               survminer,
               gridExtra,
               png,
               grid,
               Gmisc)
source('scripts/R/setup.R')


install_github("Auburngrads/DODschools")

options(knitr.table.format = "latex")
options(kableExtra.latex.load_packages = FALSE)
library(kableExtra)

#source('scripts/R/setup.R')

#BIB <- ReadBib('references/my_bib.bib')
#knitcitations <- BIB[title = 'knitcitations']
#refmanager    <- BIB[title = 'RefManageR']
#pressure      <- BIB[key = 'randolph2016']
#cite_options(citation_format = 'pandoc')
```

# Introduction

## Background

Countries around the world have always entered in and out of conflict over time. To gain an understanding into these transitions, mdoels have been developed to predict when a country's conflict status will change. Variables have been identified that largely influence which direction a country moves. The Heidelberg Insititue for International Conflict Research (HIIK) has tracked conflict around the world and provided the data used for previous model building and this research. Using previously developed logistic regression models, this analsyis will investigate the nation specific Markov models for the probability of whether a state's conflict staus remains constant or changes. From these Markov models, the expected transition times, mean recurrence, and long-run time for each nation's conflict status can be found. 

The Markov models alone provide forecasts into future conflict that go beyond the capabilites of logisitc regression. Manipulating each Markov model is the starting point for identifying future nation's conflict trends. 

## Problem Statement

Fill the missing observations in the data set utilized by Neumann's research with optimal imutation methods. Develop regression models for the Neumann's selected variables of interest in the Arab and South East Asia regions. Iteratively create future alternative scenarios for country transitions in and out of conflict. 

## Research Objectives

The objective of this study is to see how future alternatives of country conflict will look using an interative method based on a modified Bayesian multiple imputations. 

## Research Questions

This study seeks to answer the following research questions on the future conflict scenarios for the Arab and South East world regions. 

**Question 1**

How should the data set utilized in the Neumann study be imputed?




## Assumptions and Limitations

## Overview

# Literature Review

## Overview

The purpose of this chapter is to provide insight gained froms previous influential research done on country conflict prediction and understaning into the statistical methods practiced in this research's forecasting analysis.

## Nation-State Conflict Prediction Models

Predicting world conflict has been a problem addressed by multiple studies. There have been different prediction methologies and ways researchers have defined conflict or the relevant variables. There have been varying accuracies these predictive models have achieved. This section outlines the current progress already made on predicting that will be the basis of this researches work on alternative future analysis of world conflict.

The study, _A Global Forecasting Model of Political Instability_, conducted by Dr. Jack Goldstone for the U.S. Central Intelligence Agency's Directorate of Intelligence predicted the onset of political instability two years prior to the conflict's start (CITE Goldstone). The research took open source global data from 1955 to 2003 and performed a variety of prediction techniques with an achieved high, 80\% accuracy distinguishing between countries that experienced instability from those that remained stable (CITE Goldstone). The study found a nonlinear five-category measure of regime type to be the most powerful predictor rather than economic conditions, demography, or geography (CITE Goldstone). Conflict, the dependent variable, was defined by the study as a Revolutionary War, Ethnic War, Adverse Regime Changes, or Genocides and Politicides (CITE Goldstone). Of the predictive event history models, logistic regression, neural networks, and Markov processess tested, the simple logisitc regression model performed best with only four independent variables. These results gave insight for future researchs to the importance of fewer, major variables in conflict models as well as logistic regression being a favorable method political instability prediction.



## Bayesian Forecasting

# Methodology

## Overview

This research explores imputation techniques to first fill missing gaps int the data and develop linear regression models to develop future alternatives of nation-state conflict for two major world regions. Section 3.2 describes the methodology used to develop the data set and imputation methods used to complete the data's missing observations. Section 3.3 outlines the development and building procedures for the linear regression models for each variable of interest. Section 3.4 

```{r, engine="tikz", eval = TRUE, fig.cap = "Methodology Overview", echo=FALSE, fig.width=30, fig.height=30}

\tikzstyle{block} = [rectangle, draw, fill=blue!20, 
text width=9em, text centered, rounded corners, minimum height=4em]
#\tikzstyle{line} = [draw, -latex']

#\usetikzlibrary{arrows}
\usetikzlibrary{arrows.meta}
\tikzstyle{arrow} = [draw, >=angle 90, thick]

\begin{tikzpicture}[node distance = 2cm, auto, >= triangle 60]
    % nodes
    \node [block] (init) {\Large Multiple Imputation of Multivariate Missing Data};
    \node [block, right of = init, node distance = 5cm] (sec) {\Large Develop Regression Models Variables of Interest};
    \node [block, right of = sec, node distance = 5cm] (third) {\Large Regression Model Analysis};
    \node [block, below of = init, node distance = 3.5cm] (four) {\large Set Trend of Chosen Variable};
    \node [block, right of = four, node distance = 5cm] (fifth) {\Large Derive One Step Forward using Regression Models};
    \node [block, right of = fifth, node distance = 5cm] (six) {\Large Complete Future Data};
    \node [block, below of = four, node distance = 3.5cm] (sev) {\Large Utilize Logistic Regression Models};
    \node [block, right of = sev, node distance = 5cm] (eight) {\Large Simulate Results using Markov Model};
    \node [block, right of = eight, node distance = 5cm] (nine) {\Large Analyze Alternative Futures};
    
    \path [line] (init) -- (sec);
    \path [line] (sec) -- (third);
    \path [line] (third) |- ([xshift = 0cm, yshift = -1.75cm].northwest) -- (four);
    \path [line] (four) -- (fifth);
    \path [line] (fifth) -- (six);
    \path [line] (six) |- ([xshift = 0cm, yshift = -5.5cm].northwest) -- (sev);
    \path [line] 
      (sev) edge (eight)
      (eight) edge (nine);
\end{tikzpicture}

```

## Imputation 

### Original Data Set

The data utilized by this study is the same as the Neumann (CITE Neumann) study and build upond the Leiby (CITE) and Shallcross (CITE) studies. The data initially consisted of 182 countries from the Neumann, Leiby, and Shallcross studies from the 2004-2014 and the same independent variables analyzed by the Neumann's research. This study still imputed and used the Military Expenditure as a percent of government spending despite Neumann (CITE) removing from her work because of a high percentage of the variable being unobserved. This research added the same two additional technology variables, two derived border conflcit variables inspired by the Leiby (CITE) research, and dependent conflict transition variable as the Neumann (CITE) study. These generated variables are explained in further detail after the missing data observations were first imputed.

### Missing Data

This study assumed that all of the unobserved data is missing at random. This means that probability of being missing is not the same for all cases but within that group of data's observed values (CITE Buuren). The probability that a data point is missing only depends on observed data values and not any unobserved or outside it's group. Assuming the data is missing at random is the foundation for this research's applied imputation methods. The original data was missing observations for 21 of the 32 variables over the past ten years. The missing observations accounted for about 6.79\% of the data's total observations. After splitting the data by region, the missingness per region ranged between 3.22\% and 9.05\% of the entire regions observations. 

Before applying more complex imputation methods, the variable Polity IV's missing observations were filled using information provided by the fully observed Regime Type variable. Goldstone's CIA study created the Regime Type variable as an indicator of political instability (CITE Neumann #7). Regime type originally had 57 descriptors of a country's government, and Boekstein simplified the variable down to just a three level indicator (CITE Neumann #15). Regime type is observable and constant each year for every country analyzed in this study. The Polity IV is an integer variable ranging from -10 to 10 where a -10 means a country's government is fully autocratic and 10 fully democratic. Specific Polity IV indicators were given to those country's with anarchies, transitioning governments, or governments experiencing a foreign interruption. The missing observations for Polity IV were filled based on the Regime Type of a country using the mapping of the three levels of Regime Type as seen in Table XX.

```{r, xtable1, results='asis', eval=TRUE}
library(kableExtra)

Polity.transform <- data.frame(
  "Regime Type" = c("Central Ruling Party",
                  "Emerging, Transitional, Recent Change, and Disputed",
                  "Democratic"),
  'Corresponding Polity Value'   = c('-10','0','10')
)

#kableExtra::kable(text_tbl, "latex", booktabs = T) %>%
#  kable_styling(position = "center")
methods_table <- xtable::xtable(Polity.transform, caption = 'Mapping of Regime Type to Fill Missing Polity Values', label = 'table:polity.tranform', align = "llc")
print(methods_table, comment = F, include.rownames=FALSE, scalebox = 0.9, sanitize.text.function = function(x){x}, table.placement = "H")

```

Neumann's (CITE) research identified new groups of countries based on applying Modified K-Means Algorithm to the 2014 data for the selected 182 countries. The groupings found came from the algorithm's similiarities between data and location. Neumann's new groupings are how this study breaks down the 182 countries of interest, and her new COCOM 1 and 6 are the primary regions analyzed by this study. New COCOM 1 and 6 contain countries with historically violile conflict statuses which makes them of greater interest for analyzing future conflict transitions. 

### Mulitple Imputation by Chained Equations

Multiple imputation by chained equations (MICE) was the method used to impute the remaining missing observations. The MICE package in R allowed this method to be applied to each multivariate data set of Neumann's six world regions (CITE Mice R Package). Multiple imputation creates _m_ > 1 complete versions of the data by filling the missing observations with plausible data values (CITE Buuren). Using multiple imputed data sets helps address the statistical uncertainity involved with impututing data. The MICE algorithm is a fully conditional specification imputation method which means it imputes multivariate missing data in a variable-by-variable manner (CITE Buuren). MICE predicts a column of missing data as a the target variable in a regression equation with the all the other variables as the predictors unless other specified (CITE R MICE package). If a predictor is missing an observation, then the most recent iteration's imputation value is used to impute the target variable (CITE MICE package). MICE is a Markov chain Monte Carlo method in which the state space consists of of all imputed values. The MICE algorithm must satisfy three properties to converge, just as any Markov chain would converge to a stationary distribution.

  * irreducible, the chain must be able to reach all interesting parts of the state space
  * aperiodic, the chain should not oscillate between different staes
  * recurrence, all inresting parts can be reached infinitely often at least from almost all starting points
  
The first step in filling in the initial missing data observations was checking to see if the MICE algorithm was converging for each region. Van Burren identified there being no clear-cut method for determining whether the MICE algorithm has converged but that suitable imputations can be spotted from plotting one or more parameters versus the iteration number. The means and standard deviations were plotted for each variable's imputation streams. Healthy converges were categorized by freely intermingled different streams, without showing any trends and the variance between different sequences not being larger than the variance within each individual sequence. Below are an example of a healthy convergence when imputing freshwater per capita in South East Asia. 

```{r healthy convergence, eval = TRUE, fig.cap = 'Healhty-Convergence of the MICE Algorithm for Freshwater per Capita in South East Asia',echo=FALSE}
load("C:/Users/ZKane/OneDrive/Documents/KaneThesis/healthy_convergence.RData")

```

After looking at MICE applied to this analysis's data and seeing previous research's MICE convergences, around 20 iterations there was sufficient convergence by the algorithm. Moving forward each imputation conducted was run for 20 iterations. MICE allows for several different imputation techniques to be specifically applied to each variable every pass. _m_ of these chains are calculated in parallel, and after around 15-20 iterations for one regression chain, the regression coefficents for each missing variables' models are likely to converge (CITE burren page 116). MICE utilizes the columns of fully observed data in these chains. Imputing with a subset of only the missing data or simplified data set may deprive the MICE algorithm of information from the observed data. For this reason, each imputation was performed with the missing and complete columns of data. Multiple imputation procedurely will impute the data, analyze each imputed dataset seperately, and pool the results. The intital imputation began with investigating which MICE method resulted in the data most similiar to the distribution of observed data. The five mice packages tested are shown in Table XX. 

```{r, xtable2, results='asis', eval=TRUE}
library(kableExtra)

imp_methods <- data.frame(
  Method = c("cart", "pmm", "norm", "rf", "mean"),
  Description = c(
    "Classification and regression trees",
    "Predictive mean matching",
    "Bayesian linear regression",
    "Random forrest",
    "Unconditional mean imputation"
  )
)

#kableExtra::kable(text_tbl, "latex", booktabs = T) %>%
#  kable_styling(position = "center")
methods_table <- xtable::xtable(imp_methods, caption = 'Imputation Methods Tested', label = 'table:imp_methods_tested')
print(methods_table, comment = F, include.rownames=FALSE, scalebox = 0.9, sanitize.text.function = function(x){x}, table.placement = "H")
```

Between all of the six regions, there were average about 12 variables per region that required imputation by MICE. MICE has the ability to impute and utilize categorical varibales. MICE creates dummy variables for the categorical variables and generates their regressions and resulting imputations from these (CITE MICE R package). None of the variables requiring imputation were categorical, but there were categorical various such as Regime Type that were included in the prediction of other missing variables. The MICE imputation methods investigated were selected based on there not any missing categorical variables and trying to test a wide variety of methods. Imputation using classification and regression trees (CART) seek predictors and cut points in the predictors used to divide up the sample of data. The data is split up repeatidly until a binary tree is build to determine the target variable (CITE Van Buuren). CART methods for imputation are robust against outliers, can handle multicollinearity and skewed distributions, and are able to fit interations and nonlinear relationships (CITE Van Buuren). Predictive mean matching (pmm) is an imputation technique which utilizes the observed data to calculate the predicted target value. It takes a random draw from the candidate donors from the complete cases with predicted values closest to the predicted missing entry value (CITE Van Buuren). The norm method applies Bayesian linear regression that uses parameter uncertainty from random draws from a posterior probability distribution based on the observed data (CITE Van Buuren). 

### Testing Imputation Methods

Each of the five MICE methods were run to develop five different imputed data sets per region and then compared using the Kolmogorov-Smirnov (K-S) and non-parametric, 2-sample Anderson-Darling (A-D) tests. The K-S test looks at if the imputed data values are similiar to the observed data values. This test makes the assumption that the imputed data should follow the same distribution as the observed data (CITE Abayomi, Brantley #36). Engmann and Cousineau (CITE Brantley 37) compared both the A-D and K-S tests and found that the A-D performed better when analzying moments and small differences in the tails of distributions. Based on these findings, the A-D test for this analysis will be the main differentitor between imputation methods (CITE Brantely). The null hypothesis behind both of these tests is that the distributions come from the same parent distribution. A small p value indicates that the imputed data and original data are significantly different and can be interepreted as a poor imputation method. For some variables missing a high percentage of observations such as Freshwater per Capita which was missing for ~74\% of observations, no imputation method was able to find a statistical similarity between that method's imputed data and the observed data.

In some literature the mean absolute error and root mean square error have been used to assess the performance of an imputation method. This analysis didn't utilize these measures of accuracy based on the difference between true and the imputed data. Due to there being so few complete cases for certain variables, evaluation metrics that were based on knowing the true values for missing data weren't implemented. Van Buuren also detailed the shortcomings of treating imputation as a prediction problem geared towards finding the best value. The goal of multiple imputations is "to obtain statistically valid infrences from incomplete data" (CITE Van Buuren). Also treating imputations as methods to enhance the classification accuracy may favor strange imputation methods (CITE Van Buuren). For these reasons, evaluating and choosing an imputation method becomes an increasingly complex problem. Van Buuren's warning as well as the conflicting results and ties between the K-S and A-D statisitical tests begged for another imputation evaluation metric to decide the optimal method. Diagnostic graphs were implemented lastly to asses the plausibility of each imputation method: box and whisker plot and kernel density plots. The box and whisker plot was chosen over strip plots based on Van Buuren's recommendation that the box and whisker plot is more appropriate for large datasets. Both these plots compare the discrepancyies between the observed and imputed data. Dramatic differences would signify a possibility that something with the imputed data needed further investigating (CITE Van Buuren). The diagnostic plots were used to validate the results of the A-D and K-S tests as well as break any potential ties from seeing which imputed values from a given are more reasonable. For example the variable freshwater per capita from the Arab region had all five inputed values insignificantly different from the observed data when tested using the A-D and K-S tests. The box and whisker plots and density plots were then examined to learn more differences between imputation techniques. A suitable imputation technique would produce values that could be observed if the data had not been missing at all (Cite MICE Article page 42). The best performing plots had imputed data visually closest to the observed data. The diagnostic plots After applying applying the K-S and A-D statistical tests and inspecting the diagnostic plots, the imputation methods were decided for each variable in a given region. 

```{r, xtable3, results='asis', eval=TRUE, cache=TRUE}
load("C:/Users/ZKane/OneDrive/Documents/KaneThesis/completed_SE_asia.RData")
load("C:/Users/ZKane/OneDrive/Documents/KaneThesis/completed_arab_imp.RData")
load("C:/Users/ZKane/OneDrive/Documents/KaneThesis/SE_Asia_Mobile_imp.RData")

methods_SE_asia <- data.frame(jm_SE_asia$method[which(jm_SE_asia$method != "")])
methods_arab <- data.frame(jm_arab$method[which(jm_arab$method != "")])
methods_SE_asia_mobile <- data.frame(jm_SE_asia_Mobile_Cells$method["Mobile.Cell.Subs"])
names(methods_SE_asia_mobile) <- names(methods_SE_asia)
methods_SE_asia <- rbind(methods_SE_asia,methods_SE_asia_mobile)

library(data.table)
methods_arab <- setDT(methods_arab, keep.rownames = TRUE)[]
methods_SE_asia <- setDT(methods_SE_asia, keep.rownames = TRUE)[]
methods_SE_asia_mobile <- setDT(methods_SE_asia_mobile, keep.rownames = TRUE)[]
methods <- merge(methods_arab, methods_SE_asia, by = "rn", all = TRUE)
colnames(methods) <- c("Variable", "Arab", "South East Asia")
library(xtable)

xtd2 <- xtable::xtable(methods, caption = 'Imputation Methods Used for Each Variable by Region',
                       align = "llcc", label = 'table:imp_methods')
print(xtd2, comment = F, include.rownames=FALSE, scalebox = 0.8,
      sanitize.text.function = function(x){x}, table.placement = "H")
```

### Imputation Challenges

A problem that aross specifically with the South East Asia region is some variables are linearly related. When the MICE algorithm builds the regression equation to predict a missing value, a variable that is a linear combination of another will result in a singularity error that breaks the MICE algorithm. To fix this, the redundent variables must be excluded from the set of predictor variables used by MICE. The dependent variables can be identified by the last eigenvector of the covariance matrix of the data after performing listwise deletion. The variable Mobile Cell Subscriptions was highly correlated ($>0.5$) with multiple variables. Mobile Cell Subscriptions by far had the smallest loading ($2.012761e-11$) on the on the last eigenvector of the covariance matrix. For these reasons Mobile Cell Subscriptions was imputed individually using the MICE algorithm. When removed the singularity errors ceased to disrupt the MICE algorithm.  


## Regression Models

With the complete data from the previous ten years since 2014, linear regression models were built for each variable of interest. Neumann's model's for regions in and out of conflict defined the variable that would be of interest for this research. The variables required in Neumann's models will be required to predict future conflict transitions. The regression equations define each variable to be explained by the rest of the data. Each regression model was built with the goal of achieving the most parsimonium model from the other variables in the data. Before the regression models were build and reduced, the data set required certain variables gereated by Neumann's research be developed using the complete data. Van Buuren stressed the importance of developing imputations before any additional variables are generated (CITE Van Buuren). Additionally certain variables that are derived from the rest of the data didn't require regressions to be build since their values in future scearios can be calculated then. 

### Variable Development

After filling all the missing gaps in the data, variables of interested were developed to match the data set of previous works such as Neumann and Shellcross. A Government variable was created based on the values of the Polity variarble to indicate a nation's government type. The six categories of this variable are shown in Table \@ref(tab:govmapping).

```{r govmapping, xtable, results='asis', eval=TRUE}

Government_mapping <- data.frame(
  '1' = c("-10 to -6", "-5 to 5", "6 to 10", "-66", "-77", "-88"),
  '2' = c('0','1','2','3','4','5'),
  '3' = c("Autocratic",
                         "Emerging Democracy",
                         "Democratic",
                         "Foreign Interruption",
                         "Anarchy",
                         "Transitional")
)

#KableExtra::kable(Government_mapping, "latex", booktabs = T) %>%
#  kable_styling(position = "center")
government_table <- xtable::xtable(Government_mapping, caption = 'Goverment Type Mapping from Polity', label = 'tab:gov_mapping', align = "cccc")
names(government_table) <- c("Original Polity Value", "Government Type Number",
                             "Government Type")
print(government_table, comment = F, include.rownames=FALSE, scalebox = 0.9,
      sanitize.text.function = function(x){x}, table.placement = "H"
      )

```

The Percent Border Conflict is consistent with the percent border conflict variable in Neumann (CITE Neumann) and border conflict variable in Shallcross (CITE Shellcross) and Boekestein (CITE BOEK). The Percent Border Conflict is calculated by summing the product of all the percentages neighboring country border a country of interest and the neighboring countries HIIK level of conflict intensity for a given year. Islands were assumed to have no neighboring countries and a zero Percent Border Conflict. Equation XX defines the Percent Border Conflict Variable 
\begin{gather}
PctBC_{ij} = \sum_{k=1}^{n} H_{kj}p_{k} \text{where} \nonumber\\
n = \text{number of bordering countries for country $i$} \nonumber\\
H_{kj} = \text{HIIK conflict intensity level for country $k$ in year $j$} \nonumber\\
p_{k} = \text{percent of border country $i$ shares with county $k$} \\
i = \text{Country} \in \{1,2, ..., 182\} \nonumber\\
j = \text{Year} \in \{2004, ..., 2015\} \nonumber\\
k = \text{Bordering country} \nonumber
\end{gather}

The Average Border Conflict measures the average conflict intensity around a given country in a given year and is consistent with Neumann's (CITE Neumann) average border conflict variable. Islands are treated as having no bordering countries. The calculation for the Average Border Conflict is defined by Equation XX. 
\begin{gather}
AvgBC_{ij} = \frac{\sum_{k=1}^{n} H_{kj}}{n} \text{where} \nonumber\\
n = \text{number of bordering countries for country $i$} \nonumber\\
H_{kj} = \text{HIIK conflict intensity level for country $k$ in year $j$} \\
i = \text{Country} \in \{1,2, ..., 182\} \nonumber\\
j = \text{Year} \in \{2004, ..., 2015\} \nonumber\\
k = \text{Bordering country} \nonumber
\end{gather}

The Binary Border Conflict variable is consistent with the binary border conflict variable in both the Neumann (CITE Neumann) and Leiby (CITE Leiby) studies. It is a binary representation for a given country if one of their neighboring nations meets a certain conflict intensity in a given year. Islands are again assumed to have a zero score as they are not neighbored by any nations. Binary Border Conflict score is defined for a given country by Equation XX.
\begin{gather}
BinBC_{ij} = 
  \begin{cases}
    1 & \quad \text{if $H_{kj} \ge 3$ for any country bordering country $i$} \\
    0 & \quad \text{otherwise}
  \end{cases}
\nonumber\\
H_{kj} = \text{HIIK conflict intensity level for country $k$ in year $j$} \\
i = \text{Country} \in \{1,2, ..., 182\} \nonumber\\
j = \text{Year} \in \{2004, ..., 2015\} \nonumber\\
k = \text{Bordering country} \nonumber
\end{gather}

The dependent variable, Conflict Transition, is a binary representation if a country has changed conflict status since the previous year. Conflcit status is defined by the mapping a country's HIIK conflict intensity level in a given year. HIIK scores of 0, 1, and 2 are mapped to a 0 for the conflict status and indicate a country is not in conflict that year. HIIK scores of 3, 4, and 5 are mapped to a conflict status of 1 and represent a country is in state of conflict in that given year. The Conflict Transition binary variable for a country in a given year depends on the current and previous years conflict status. Conflict Transition is equal to 1 if the conflict status of a given year _i_ is not equal to the conflict status of the previous year _i-1_. Table XX below represents this mapping from conflict status for years _i-1_ and _i_ to the binary Conflict Transition variable in year _i_. 

```{r conflicttransitionmapping, xtable, results='asis', eval=TRUE}

conflict_transition <- data.frame(
  '1' = c("0 = Not In Conflict", "1 = In Conflict","0 = Not In Conflict", "1 = In Conflict"),
  '2' = c("0 = Not In Conflict", "1 = In Conflict","1 = In Conflict","0 = Not In Conflict"),
  '3' = c("0 = Not In Conflict", "0 = Not In Conflict","1 = In Conflict","1 = In Conflict")
)

#KableExtra::kable(Government_mapping, "latex", booktabs = T) %>%
#  kable_styling(position = "center")
conflict_transition_map <- xtable::xtable(conflict_transition, caption = 'Mapping of Conflict Transition', label = 'tab:conflict_transition_mapping', align = "ll|l|l")
names(conflict_transition_map) <- c("Conflict Status Yr $i-1$", "Conflict Status Yr $i$",
                             "Conflict Transition Yr $i$")
bold <- function(x) {paste('{\\textbf{',x,'}}', sep ='')}
print(conflict_transition_map, comment = F, include.rownames=FALSE, scalebox = 0.9,
      sanitize.text.function = function(x){x}, table.placement = "H", hline.after = c(0,2),
      sanitize.colnames.function = bold, booktabs = T
      )

```

### Model Building Procedure

Linear regression models were build for variables that were significant in Neumann's logisitic regression models that predict a country's Conflict Transition. Linear regression models were build to statistically define each individual variable of interest by the other variables in a given region. Testing was completed to include higher order terms and interaction terms in these models, but due to the higher achieved adjuste $R^2$ values, models were only build using the main effects. The complete data set used to build the models consists of all five of the imputed data sets stacked on top of each other. This goes against Van Buuren's advice to pool the resulting models, but due to the desire for point estimates defining each variable of interest, the simplier method of stacking the imputations was preferred. With less than $10\%$ of the observations missing from the two new world regions of interest, the research is impacted less from weight of the missing data. The stacked imputed data results in _m_ x _n_ complete records where _m_ still being the number of imputed data sets. The statistical analysis thus becomes a weighted linear regression with a weighted factor of $1/m$ applied to each record. Having low levels of missingness and the point estimates generated from the stacked complete data being unbiased (CITE page 158) makes treating the imputed data as a stacked, long data set sufficient for the purposes of this research.

Stepwise regression is the primary method used to generate parsimonous linear regression models for each variable. This method iteratively removes predictor variables while computing a linear regression model each time. Each time a regression is rerun, each predictor variable's associated p value is assessed to see if it is within a specified acceptable range. By deleting variables from the model, the precision of point estimates of the remaining in the model are improved (CITE intro to linear). The stepwise method was run using JMP with chosen p value for entering and removing a variable of 0.05. Stepwise regression operates in a direction to either enter or remove a term with the smallest or largest p value. The mixed option in JMP alternates between a forward and backward selection to include the only significant terms. Models were building stepping from a null and full model using the mixed selection method. Most times the reduced models were the same, but if there were any differences, the model that achieved the higher $R^2_{adj}$ was chosen. The coefficient of multiple determination, $R^2$, is a measure of model adequacy that represents the proportion of variance explained by the regression. Adding regressors to the model will improve $R^2$ but can still produce a worse model and larger error mean square by losing one degree of freedom for error (CITE intro). A low value of $R^2$ for this research indicates a poorly specified model (CITE intro). $R^2$ will never decrease from adding a variable to the model, so it is important in varaibel selection to include another evaluation statistic. $R^2_{adj}$ will only improve if the variable added reduces the residual mean square to prevent overfitting (CITE intro). This research will reference to $R^2_{adj}$ when evaulating models in stepwise regression. Interaction terms were also selectively included in models with lacking $R^2_{adj}$ (<0.5). In an effort to devleop parsimonious models, only second order interaction terms were considered. With the interactions factored into the model, the Arab region produced 74 possible variables while there were 209 possible variables in the SE Asia region. Stepwise regression reduced these numbers for the models requiring higher $R^2_{adj}$. All of the Arab region models were built with interactions, but only Population Growth's interactions were necessary in South East Asia.
  
### Assessing Model Adequacy

The final stepwise models were analyzed to ensure they met all the assumptions of linear regression. Linear Regression assumes the error terms or residuals must be independent, normal, and random variables with mean of $0$ and constant variance $\sigma^2$ (CITE data mining and analysis). Graphically, these linear regression assumptions can be evaluated using a normal probability plot of the residuals and a plot of the standardized residuals against the predicted values. A normal probability plot of the residuals is a quantile-quantile plot where quantiles of a particular distribution are plotted against the quantiles of the standard normal distribution to identify deviations from normality (CITE data mining). If a distribution is normal then a majority of the points in the graph should fall close to the diagonal reference line. Statistically, there are lot of different ways to test normality with each depending on the data at hand. The deviations from normality were calculated using the Cramer-Von Mises test where the null hypothesis is that the distribution of the errors follows a normal distrubition. It is a simplified version of the Anderson-Darling test that does not provide as much weight to the tails of the distribution. It is not the most powerful empirical distribution test, but this research choose to have more relaxed normality standards to avoid conducted more in depth outlier analysis and accept simplier models sooner. The Cramer-Von Mises statistic is calculated as,
\begin{gather}
CVM = \frac{1}{12n} + \sum_{i=1}^{n} [F_0(x_{(i)})-\frac{2i-1}{2n}]^2
\end{gather}
where $n$ is the sample size and $x_i$'s are the ordered data (CITE CVM). P value scores lower than $0.05$ indicate a regression model's errors don't follow a normally distrbuted. The package oslrr (CITE olsrr) in R was used to test the normality of each variable of interests' residuals.

A plot of the standardized residuals against the predicted values helps identify patterns in the variance of a model's residuals. Linear regression assumes homoscedasticity, constant variance, and independence of a model's error term. These plots tests both of these assumptions and should not represent any clear funnel, linear, or u-shaped pattern. If the variance of the errors is increasing or decreasing over time, confidence intervals for new predictions will tend to be unrealistic (CITE DUKE). The plots should be evenly spread out and distanced from the x-axis (CITE data mining). Statistically, these assumptions are tested using the Breusch Pagan test for homogenity of variances from the olsrr package (CITE olsrr) in R where the null hypothesis is that the variance is constant based on a chi-squared test. This test sees whether the variance of the errors from a regression is dependent on the values of the independent variables (CITE cran heter). Below in Table XX the final models' adequacy tests can be found and any respective transformations.

```{r modeladeqarab, xtable, results='asis', eval=TRUE}

load("C:/Users/ZKane/OneDrive/Documents/KaneThesis/Arab_reg_table.Rda")
load("C:/Users/ZKane/OneDrive/Documents/KaneThesis/SE_Asia_reg_table.Rda")
reg_table <- rbind (Arab_reg_table, SE_Asia_reg_table)
reg_table[c(2,4,6,8:10,12,13),5] <- "<0.0001"
reg_map <- xtable::xtable(reg_table, caption = 'Regression Model Adequacy Check', label = 'tab:reg_models', align = "lcccccc", digits=c(0,4,4,4,4,4,4))

names(reg_map) <- c("$R^2$", "$R^2_{adj}$", "F-Test",
                             "Cramer-Von Mises", "Normality", "Transformation")
rownames(reg_map) <- c("Arab Mobile Cell Subscriptions","Arab Population Density","Arab Percent Border Conflict","Arab Fertility Rate","Arab Trade Percent GDP","SE Asia Internet Users","SE Asia Life Expectancy","SE Asia Mobile Cell Subs","SE Infant Mortality Rate","SE Asia Population Growth","SE Asia Arable Lands","SE Asia Avg Border Conflict", "SE Asia Freshwater per Capita")
#bold <- function(x) {paste('{\\textbf{',x,'}}', sep ='')}
print(reg_map, comment = F, scalebox = 0.75,
      sanitize.text.function = function(x){x}, table.placement = "H",
      booktabs = T, include.rownames = TRUE
      )

```

### Transformations

Certain variables regression models were improved after the dependent variarbles were transformed. These transformations were performed to possible improved the model's $R^2_{adj}$, normality, or homoscedasticity statistics. If a transformation tested raised any of these categories, then the transformation was made for model from here on out. The square root was taken for the Population Density variable in the Arab region ($\sqrt{Population Density}$). The transformation improved a higher $R^2_{adj}$ but didn't improve the model's homoscedasticity or nomarlity violations. The log was taken of a few variables which helped some of those models to fulfill the linear regression assumptions ($log(y_i)=\beta_0+\beta_{1}x_{1i}+...+\beta_kx_{ki}+e_i$). Mobile Cell Subscriptions in the South East Asia region was transformed initally just by the square root, but the model continued to improve further by then taking the fourth root ($\sqrt[4]{Mobile Cell Subscriptions}$). JMP offered other transformations that were tested but didn't out perform the three ones (log, square root, and fourth root) that were actually done. 

Even after the transformations were added, the regression models didn't statistically meet all of the assumptions of linear regression. This research recognizes the discrepencies in the models, but accepts the models, and will proceed with them for developing future alternatives of world conflict. 

## Iterative Forecasting 


# Analysis And Results

This is the fourth chapter of your thesis

# Conclusion

This is the final chapter of your thesis.












